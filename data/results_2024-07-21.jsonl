{"Title":"Sparse vs Contiguous Adversarial Pixel Perturbations in Multimodal Models: An Empirical Analysis","Primary Category":"cs.CV","Categories":["cs.CV","cs.CR","cs.LG","I.2.0; I.4.0"],"Summary":"Assessing the robustness of multimodal models against adversarial examples is\nan important aspect for the safety of its users. We craft L0-norm perturbation\nattacks on the preprocessed input images. We launch them in a black-box setup\nagainst four multimodal models and two unimodal DNNs, considering both targeted\nand untargeted misclassification. Our attacks target less than 0.04% of\nperturbed image area and integrate different spatial positioning of perturbed\npixels: sparse positioning and pixels arranged in different contiguous shapes\n(row, column, diagonal, and patch). To the best of our knowledge, we are the\nfirst to assess the robustness of three state-of-the-art multimodal models\n(ALIGN, AltCLIP, GroupViT) against different sparse and contiguous pixel\ndistribution perturbations. The obtained results indicate that unimodal DNNs\nare more robust than multimodal models. Furthermore, models using CNN-based\nImage Encoder are more vulnerable than models with ViT - for untargeted\nattacks, we obtain a 99% success rate by perturbing less than 0.02% of the\nimage area.","Link":"http://arxiv.org/pdf/2407.18251v1","Published":1721930388}
{"Title":"Trajectory-aligned Space-time Tokens for Few-shot Action Recognition","Primary Category":"cs.CV","Categories":["cs.CV"],"Summary":"We propose a simple yet effective approach for few-shot action recognition,\nemphasizing the disentanglement of motion and appearance representations. By\nharnessing recent progress in tracking, specifically point trajectories and\nself-supervised representation learning, we build trajectory-aligned tokens\n(TATs) that capture motion and appearance information. This approach\nsignificantly reduces the data requirements while retaining essential\ninformation. To process these representations, we use a Masked Space-time\nTransformer that effectively learns to aggregate information to facilitate\nfew-shot action recognition. We demonstrate state-of-the-art results on\nfew-shot action recognition across multiple datasets. Our project page is\navailable at https://www.cs.umd.edu/~pulkit/tats","Link":"http://arxiv.org/pdf/2407.18249v1","Published":1721930371}
{"Title":"Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning","Primary Category":"cs.CL","Categories":["cs.CL"],"Summary":"Effective training of language models (LMs) for mathematical reasoning tasks\ndemands high-quality supervised fine-tuning data. Besides obtaining annotations\nfrom human experts, a common alternative is sampling from larger and more\npowerful LMs. However, this knowledge distillation approach can be costly and\nunstable, particularly when relying on closed-source, proprietary LMs like\nGPT-4, whose behaviors are often unpredictable. In this work, we demonstrate\nthat the reasoning abilities of small-scale LMs can be enhanced through\nself-training, a process where models learn from their own outputs. We also\nshow that the conventional self-training can be further augmented by a\npreference learning algorithm called Direct Preference Optimization (DPO). By\nintegrating DPO into self-training, we leverage preference data to guide LMs\ntowards more accurate and diverse chain-of-thought reasoning. We evaluate our\nmethod across various mathematical reasoning tasks using different base models.\nOur experiments show that this approach not only improves LMs' reasoning\nperformance but also offers a more cost-effective and scalable solution\ncompared to relying on large proprietary LMs.","Link":"http://arxiv.org/pdf/2407.18248v1","Published":1721930356}
{"Title":"VGGHeads: A Large-Scale Synthetic Dataset for 3D Human Heads","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Human head detection, keypoint estimation, and 3D head model fitting are\nimportant tasks with many applications. However, traditional real-world\ndatasets often suffer from bias, privacy, and ethical concerns, and they have\nbeen recorded in laboratory environments, which makes it difficult for trained\nmodels to generalize. Here, we introduce VGGHeads -- a large scale synthetic\ndataset generated with diffusion models for human head detection and 3D mesh\nestimation. Our dataset comprises over 1 million high-resolution images, each\nannotated with detailed 3D head meshes, facial landmarks, and bounding boxes.\nUsing this dataset we introduce a new model architecture capable of\nsimultaneous heads detection and head meshes reconstruction from a single image\nin a single step. Through extensive experimental evaluations, we demonstrate\nthat models trained on our synthetic data achieve strong performance on real\nimages. Furthermore, the versatility of our dataset makes it applicable across\na broad spectrum of tasks, offering a general and comprehensive representation\nof human heads. Additionally, we provide detailed information about the\nsynthetic data generation pipeline, enabling it to be re-used for other tasks\nand domains.","Link":"http://arxiv.org/pdf/2407.18245v1","Published":1721930297}
{"Title":"LoRA-Pro: Are Low-Rank Adapters Properly Optimized?","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI","cs.CL"],"Summary":"Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method\nfor parameter-efficient fine-tuning foundation models by re-parameterizing the\noriginal matrix into the product of two low-rank matrices. Despite its\nefficiency, LoRA often yields inferior performance compared to full\nfine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap.\nFirstly, we delve into the optimization processes in LoRA and full fine-tuning.\nWe reveal that while LoRA employs low-rank approximation, it neglects to\napproximate the optimization process of full fine-tuning. To address this, we\nintroduce a novel concept called the \"equivalent gradient.\" This virtual\ngradient makes the optimization process on the re-parameterized matrix\nequivalent to LoRA, which can be used to quantify the differences between LoRA\nand full fine-tuning. The equivalent gradient is derived from the gradients of\nmatrices $A$ and $B$. To narrow the performance gap, our approach minimizes the\ndifferences between the equivalent gradient and the gradient obtained from full\nfine-tuning during the optimization process. By solving this objective, we\nderive optimal closed-form solutions for updating matrices $A$ and $B$. Our\nmethod constrains the optimization process, shrinking the performance gap\nbetween LoRA and full fine-tuning. Extensive experiments on natural language\nprocessing tasks validate the effectiveness of our method.","Link":"http://arxiv.org/pdf/2407.18242v1","Published":1721930232}
{"Title":"Numerical Literals in Link Prediction: A Critical Examination of Models and Datasets","Primary Category":"cs.LG","Categories":["cs.LG","cs.DB"],"Summary":"Link Prediction(LP) is an essential task over Knowledge Graphs(KGs),\ntraditionally focussed on using and predicting the relations between entities.\nTextual entity descriptions have already been shown to be valuable, but models\nthat incorporate numerical literals have shown minor improvements on existing\nbenchmark datasets. It is unclear whether a model is actually better in using\nnumerical literals, or better capable of utilizing the graph structure. This\nraises doubts about the effectiveness of these methods and about the\nsuitability of the existing benchmark datasets.\n  We propose a methodology to evaluate LP models that incorporate numerical\nliterals. We propose i) a new synthetic dataset to better understand how well\nthese models use numerical literals and ii) dataset ablations strategies to\ninvestigate potential difficulties with the existing datasets. We identify a\nprevalent trend: many models underutilize literal information and potentially\nrely on additional parameters for performance gains. Our investigation\nhighlights the need for more extensive evaluations when releasing new models\nand datasets.","Link":"http://arxiv.org/pdf/2407.18241v1","Published":1721930133}
{"Title":"Automated Ensemble Multimodal Machine Learning for Healthcare","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"The application of machine learning in medicine and healthcare has led to the\ncreation of numerous diagnostic and prognostic models. However, despite their\nsuccess, current approaches generally issue predictions using data from a\nsingle modality. This stands in stark contrast with clinician decision-making\nwhich employs diverse information from multiple sources. While several\nmultimodal machine learning approaches exist, significant challenges in\ndeveloping multimodal systems remain that are hindering clinical adoption. In\nthis paper, we introduce a multimodal framework, AutoPrognosis-M, that enables\nthe integration of structured clinical (tabular) data and medical imaging using\nautomated machine learning. AutoPrognosis-M incorporates 17 imaging models,\nincluding convolutional neural networks and vision transformers, and three\ndistinct multimodal fusion strategies. In an illustrative application using a\nmultimodal skin lesion dataset, we highlight the importance of multimodal\nmachine learning and the power of combining multiple fusion strategies using\nensemble learning. We have open-sourced our framework as a tool for the\ncommunity and hope it will accelerate the uptake of multimodal machine learning\nin healthcare and spur further innovation.","Link":"http://arxiv.org/pdf/2407.18227v1","Published":1721929598}
{"Title":"Recursive Introspection: Teaching Language Model Agents How to Self-Improve","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI","cs.CL"],"Summary":"A central piece in enabling intelligent agentic behavior in foundation models\nis to make them capable of introspecting upon their behavior, reasoning, and\ncorrecting their mistakes as more computation or interaction is available. Even\nthe strongest proprietary large language models (LLMs) do not quite exhibit the\nability of continually improving their responses sequentially, even in\nscenarios where they are explicitly told that they are making a mistake. In\nthis paper, we develop RISE: Recursive IntroSpEction, an approach for\nfine-tuning LLMs to introduce this capability, despite prior work hypothesizing\nthat this capability may not be possible to attain. Our approach prescribes an\niterative fine-tuning procedure, which attempts to teach the model how to alter\nits response after having executed previously unsuccessful attempts to solve a\nhard test-time problem, with optionally additional environment feedback. RISE\nposes fine-tuning for a single-turn prompt as solving a multi-turn Markov\ndecision process (MDP), where the initial state is the prompt. Inspired by\nprinciples in online imitation learning and reinforcement learning, we propose\nstrategies for multi-turn data collection and training so as to imbue an LLM\nwith the capability to recursively detect and correct its previous mistakes in\nsubsequent iterations. Our experiments show that RISE enables Llama2, Llama3,\nand Mistral models to improve themselves with more turns on math reasoning\ntasks, outperforming several single-turn strategies given an equal amount of\ninference-time computation. We also find that RISE scales well, often attaining\nlarger benefits with more capable models. Our analysis shows that RISE makes\nmeaningful improvements to responses to arrive at the correct solution for\nchallenging prompts, without disrupting one-turn abilities as a result of\nexpressing more complex distributions.","Link":"http://arxiv.org/pdf/2407.18219v1","Published":1721928959}
{"Title":"Tool-Assisted Learning of Computational Reductions","Primary Category":"cs.CY","Categories":["cs.CY","cs.HC"],"Summary":"Computational reductions are an important and powerful concept in computer\nscience. However, they are difficult for many students to grasp. In this paper,\nwe outline a concept for how the learning of reductions can be supported by\neducational support systems. We present an implementation of the concept within\nsuch a system, concrete web-based and interactive learning material for\nreductions, and report on our experiences using the material in a large\nintroductory course on theoretical computer science.","Link":"http://arxiv.org/pdf/2407.18215v1","Published":1721928510}
{"Title":"Exploring Scaling Trends in LLM Robustness","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI","cs.CL","cs.CR","I.2.7"],"Summary":"Language model capabilities predictably improve from scaling a model's size\nand training data. Motivated by this, increasingly large language models have\nbeen trained, yielding an array of impressive capabilities. Yet these models\nare vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models\nto perform undesired behaviors, posing a significant risk of misuse. Prior work\nindicates that computer vision models become more robust with model and data\nscaling, raising the question: does language model robustness also improve with\nscale? We study this question empirically, finding that larger models respond\nsubstantially better to adversarial training, but there is little to no benefit\nfrom model scale in the absence of explicit defenses.","Link":"http://arxiv.org/pdf/2407.18213v1","Published":1721928401}
{"Title":"Geometry Fidelity for Spherical Images","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Spherical or omni-directional images offer an immersive visual format\nappealing to a wide range of computer vision applications. However, geometric\nproperties of spherical images pose a major challenge for models and metrics\ndesigned for ordinary 2D images. Here, we show that direct application of\nFr\\'echet Inception Distance (FID) is insufficient for quantifying geometric\nfidelity in spherical images. We introduce two quantitative metrics accounting\nfor geometric constraints, namely Omnidirectional FID (OmniFID) and\nDiscontinuity Score (DS). OmniFID is an extension of FID tailored to\nadditionally capture field-of-view requirements of the spherical format by\nleveraging cubemap projections. DS is a kernel-based seam alignment score of\ncontinuity across borders of 2D representations of spherical images. In\nexperiments, OmniFID and DS quantify geometry fidelity issues that are\nundetected by FID.","Link":"http://arxiv.org/pdf/2407.18207v1","Published":1721927830}
{"Title":"Geometry Fidelity for Spherical Images","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Spherical or omni-directional images offer an immersive visual format\nappealing to a wide range of computer vision applications. However, geometric\nproperties of spherical images pose a major challenge for models and metrics\ndesigned for ordinary 2D images. Here, we show that direct application of\nFr\\'echet Inception Distance (FID) is insufficient for quantifying geometric\nfidelity in spherical images. We introduce two quantitative metrics accounting\nfor geometric constraints, namely Omnidirectional FID (OmniFID) and\nDiscontinuity Score (DS). OmniFID is an extension of FID tailored to\nadditionally capture field-of-view requirements of the spherical format by\nleveraging cubemap projections. DS is a kernel-based seam alignment score of\ncontinuity across borders of 2D representations of spherical images. In\nexperiments, OmniFID and DS quantify geometry fidelity issues that are\nundetected by FID.","Link":"http://arxiv.org/pdf/2407.18207v1","Published":1721927830}
{"Title":"Geometry Fidelity for Spherical Images","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Spherical or omni-directional images offer an immersive visual format\nappealing to a wide range of computer vision applications. However, geometric\nproperties of spherical images pose a major challenge for models and metrics\ndesigned for ordinary 2D images. Here, we show that direct application of\nFr\\'echet Inception Distance (FID) is insufficient for quantifying geometric\nfidelity in spherical images. We introduce two quantitative metrics accounting\nfor geometric constraints, namely Omnidirectional FID (OmniFID) and\nDiscontinuity Score (DS). OmniFID is an extension of FID tailored to\nadditionally capture field-of-view requirements of the spherical format by\nleveraging cubemap projections. DS is a kernel-based seam alignment score of\ncontinuity across borders of 2D representations of spherical images. In\nexperiments, OmniFID and DS quantify geometry fidelity issues that are\nundetected by FID.","Link":"http://arxiv.org/pdf/2407.18207v1","Published":1721927830}
{"Title":"Sparse Incremental Aggregation in Multi-Hop Federated Learning","Primary Category":"cs.DC","Categories":["cs.DC","cs.LG","eess.SP"],"Summary":"This paper investigates federated learning (FL) in a multi-hop communication\nsetup, such as in constellations with inter-satellite links. In this setup,\npart of the FL clients are responsible for forwarding other client's results to\nthe parameter server. Instead of using conventional routing, the communication\nefficiency can be improved significantly by using in-network model aggregation\nat each intermediate hop, known as incremental aggregation (IA). Prior works\n[1] have indicated diminishing gains for IA under gradient sparsification. Here\nwe study this issue and propose several novel correlated sparsification methods\nfor IA. Numerical results show that, for some of these algorithms, the full\npotential of IA is still available under sparsification without impairing\nconvergence. We demonstrate a 15x improvement in communication efficiency over\nconventional routing and a 11x improvement over state-of-the-art (SoA) sparse\nIA.","Link":"http://arxiv.org/pdf/2407.18200v1","Published":1721927362}
{"Title":"AsEP: Benchmarking Deep Learning Methods for Antibody-specific Epitope Prediction","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Epitope identification is vital for antibody design yet challenging due to\nthe inherent variability in antibodies. While many deep learning methods have\nbeen developed for general protein binding site prediction tasks, whether they\nwork for epitope prediction remains an understudied research question. The\nchallenge is also heightened by the lack of a consistent evaluation pipeline\nwith sufficient dataset size and epitope diversity. We introduce a filtered\nantibody-antigen complex structure dataset, AsEP (Antibody-specific Epitope\nPrediction). AsEP is the largest of its kind and provides clustered epitope\ngroups, allowing the community to develop and test novel epitope prediction\nmethods. AsEP comes with an easy-to-use interface in Python and pre-built graph\nrepresentations of each antibody-antigen complex while also supporting\ncustomizable embedding methods. Based on this new dataset, we benchmarked\nvarious representative general protein-binding site prediction methods and find\nthat their performances are not satisfactory as expected for epitope\nprediction. We thus propose a new method, WALLE, that leverages both protein\nlanguage models and graph neural networks. WALLE demonstrate about 5X\nperformance gain over existing methods. Our empirical findings evidence that\nepitope prediction benefits from combining sequential embeddings provided by\nlanguage models and geometrical information from graph representations,\nproviding a guideline for future method design. In addition, we reformulate the\ntask as bipartite link prediction, allowing easy model performance attribution\nand interpretability. We open-source our data and code at\nhttps://github.com/biochunan/AsEP-dataset.","Link":"http://arxiv.org/pdf/2407.18184v1","Published":1721925836}
{"Title":"Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI"],"Summary":"Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing\n(scRNA-seq) data is a complex challenge that requires capturing the intricate\nrelationships between genes and their regulatory interactions. In this study,\nwe tackle this challenge by leveraging the single-cell BERT-based pre-trained\ntransformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to\naugment structured biological knowledge from existing GRNs. We introduce a\nnovel joint graph learning approach that combines the rich contextual\nrepresentations learned by pre-trained single-cell language models with the\nstructured knowledge encoded in GRNs using graph neural networks (GNNs). By\nintegrating these two modalities, our approach effectively reasons over boththe\ngene expression level constraints provided by the scRNA-seq data and the\nstructured biological knowledge inherent in GRNs. We evaluate our method on\nhuman cell benchmark datasets from the BEELINE study with cell type-specific\nground truth networks. The results demonstrate superior performance over\ncurrent state-of-the-art baselines, offering a deeper understanding of cellular\nregulatory mechanisms.","Link":"http://arxiv.org/pdf/2407.18181v1","Published":1721925728}
{"Title":"Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI"],"Summary":"Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing\n(scRNA-seq) data is a complex challenge that requires capturing the intricate\nrelationships between genes and their regulatory interactions. In this study,\nwe tackle this challenge by leveraging the single-cell BERT-based pre-trained\ntransformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to\naugment structured biological knowledge from existing GRNs. We introduce a\nnovel joint graph learning approach that combines the rich contextual\nrepresentations learned by pre-trained single-cell language models with the\nstructured knowledge encoded in GRNs using graph neural networks (GNNs). By\nintegrating these two modalities, our approach effectively reasons over boththe\ngene expression level constraints provided by the scRNA-seq data and the\nstructured biological knowledge inherent in GRNs. We evaluate our method on\nhuman cell benchmark datasets from the BEELINE study with cell type-specific\nground truth networks. The results demonstrate superior performance over\ncurrent state-of-the-art baselines, offering a deeper understanding of cellular\nregulatory mechanisms.","Link":"http://arxiv.org/pdf/2407.18181v1","Published":1721925728}
{"Title":"PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI","cs.RO"],"Summary":"In this work, we introduce PianoMime, a framework for training a\npiano-playing agent using internet demonstrations. The internet is a promising\nsource of large-scale demonstrations for training our robot agents. In\nparticular, for the case of piano-playing, Youtube is full of videos of\nprofessional pianists playing a wide myriad of songs. In our work, we leverage\nthese demonstrations to learn a generalist piano-playing agent capable of\nplaying any arbitrary song. Our framework is divided into three parts: a data\npreparation phase to extract the informative features from the Youtube videos,\na policy learning phase to train song-specific expert policies from the\ndemonstrations and a policy distillation phase to distil the policies into a\nsingle generalist agent. We explore different policy designs to represent the\nagent and evaluate the influence of the amount of training data on the\ngeneralization capability of the agent to novel songs not available in the\ndataset. We show that we are able to learn a policy with up to 56\\% F1 score on\nunseen songs.","Link":"http://arxiv.org/pdf/2407.18178v1","Published":1721925427}
{"Title":"Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI","cs.CV"],"Summary":"Vision transformers (ViTs) have demonstrated their superior accuracy for\ncomputer vision tasks compared to convolutional neural networks (CNNs).\nHowever, ViT models are often computation-intensive for efficient deployment on\nresource-limited edge devices. This work proposes Quasar-ViT, a\nhardware-oriented quantization-aware architecture search framework for ViTs, to\ndesign efficient ViT models for hardware implementation while preserving the\naccuracy. First, Quasar-ViT trains a supernet using our row-wise flexible\nmixed-precision quantization scheme, mixed-precision weight entanglement, and\nsupernet layer scaling techniques. Then, it applies an efficient\nhardware-oriented search algorithm, integrated with hardware latency and\nresource modeling, to determine a series of optimal subnets from supernet under\ndifferent inference latency targets. Finally, we propose a series of\nmodel-adaptive designs on the FPGA platform to support the architecture search\nand mitigate the gap between the theoretical computation reduction and the\npractical inference speedup. Our searched models achieve 101.5, 159.6, and\n251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA\nwith 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet\ndataset, consistently outperforming prior works.","Link":"http://arxiv.org/pdf/2407.18175v1","Published":1721925346}
{"Title":"RIDA: A Robust Attack Framework on Incomplete Graphs","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Graph Neural Networks (GNNs) are vital in data science but are increasingly\nsusceptible to adversarial attacks. To help researchers develop more robust GNN\nmodels, it's essential to focus on designing strong attack models as\nfoundational benchmarks and guiding references. Among adversarial attacks,\ngray-box poisoning attacks are noteworthy due to their effectiveness and fewer\nconstraints. These attacks exploit GNNs' need for retraining on updated data,\nthereby impacting their performance by perturbing these datasets. However,\ncurrent research overlooks the real-world scenario of incomplete graphs.To\naddress this gap, we introduce the Robust Incomplete Deep Attack Framework\n(RIDA). It is the first algorithm for robust gray-box poisoning attacks on\nincomplete graphs. The approach innovatively aggregates distant vertex\ninformation and ensures powerful data utilization.Extensive tests against 9\nSOTA baselines on 3 real-world datasets demonstrate RIDA's superiority in\nhandling incompleteness and high attack performance on the incomplete graph.","Link":"http://arxiv.org/pdf/2407.18170v1","Published":1721925215}
{"Title":"RIDA: A Robust Attack Framework on Incomplete Graphs","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Graph Neural Networks (GNNs) are vital in data science but are increasingly\nsusceptible to adversarial attacks. To help researchers develop more robust GNN\nmodels, it's essential to focus on designing strong attack models as\nfoundational benchmarks and guiding references. Among adversarial attacks,\ngray-box poisoning attacks are noteworthy due to their effectiveness and fewer\nconstraints. These attacks exploit GNNs' need for retraining on updated data,\nthereby impacting their performance by perturbing these datasets. However,\ncurrent research overlooks the real-world scenario of incomplete graphs.To\naddress this gap, we introduce the Robust Incomplete Deep Attack Framework\n(RIDA). It is the first algorithm for robust gray-box poisoning attacks on\nincomplete graphs. The approach innovatively aggregates distant vertex\ninformation and ensures powerful data utilization.Extensive tests against 9\nSOTA baselines on 3 real-world datasets demonstrate RIDA's superiority in\nhandling incompleteness and high attack performance on the incomplete graph.","Link":"http://arxiv.org/pdf/2407.18170v1","Published":1721925215}
{"Title":"RIDA: A Robust Attack Framework on Incomplete Graphs","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Graph Neural Networks (GNNs) are vital in data science but are increasingly\nsusceptible to adversarial attacks. To help researchers develop more robust GNN\nmodels, it's essential to focus on designing strong attack models as\nfoundational benchmarks and guiding references. Among adversarial attacks,\ngray-box poisoning attacks are noteworthy due to their effectiveness and fewer\nconstraints. These attacks exploit GNNs' need for retraining on updated data,\nthereby impacting their performance by perturbing these datasets. However,\ncurrent research overlooks the real-world scenario of incomplete graphs.To\naddress this gap, we introduce the Robust Incomplete Deep Attack Framework\n(RIDA). It is the first algorithm for robust gray-box poisoning attacks on\nincomplete graphs. The approach innovatively aggregates distant vertex\ninformation and ensures powerful data utilization.Extensive tests against 9\nSOTA baselines on 3 real-world datasets demonstrate RIDA's superiority in\nhandling incompleteness and high attack performance on the incomplete graph.","Link":"http://arxiv.org/pdf/2407.18170v1","Published":1721925215}
{"Title":"RIDA: A Robust Attack Framework on Incomplete Graphs","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Graph Neural Networks (GNNs) are vital in data science but are increasingly\nsusceptible to adversarial attacks. To help researchers develop more robust GNN\nmodels, it's essential to focus on designing strong attack models as\nfoundational benchmarks and guiding references. Among adversarial attacks,\ngray-box poisoning attacks are noteworthy due to their effectiveness and fewer\nconstraints. These attacks exploit GNNs' need for retraining on updated data,\nthereby impacting their performance by perturbing these datasets. However,\ncurrent research overlooks the real-world scenario of incomplete graphs.To\naddress this gap, we introduce the Robust Incomplete Deep Attack Framework\n(RIDA). It is the first algorithm for robust gray-box poisoning attacks on\nincomplete graphs. The approach innovatively aggregates distant vertex\ninformation and ensures powerful data utilization.Extensive tests against 9\nSOTA baselines on 3 real-world datasets demonstrate RIDA's superiority in\nhandling incompleteness and high attack performance on the incomplete graph.","Link":"http://arxiv.org/pdf/2407.18170v1","Published":1721925215}
{"Title":"StraightLine: An End-to-End Resource-Aware Scheduler for Machine Learning Application Requests","Primary Category":"cs.DC","Categories":["cs.DC","cs.LG"],"Summary":"The life cycle of machine learning (ML) applications consists of two stages:\nmodel development and model deployment. However, traditional ML systems (e.g.,\ntraining-specific or inference-specific systems) focus on one particular stage\nor phase of the life cycle of ML applications. These systems often aim at\noptimizing model training or accelerating model inference, and they frequently\nassume homogeneous infrastructure, which may not always reflect real-world\nscenarios that include cloud data centers, local servers, containers, and\nserverless platforms. We present StraightLine, an end-to-end resource-aware\nscheduler that schedules the optimal resources (e.g., container, virtual\nmachine, or serverless) for different ML application requests in a hybrid\ninfrastructure. The key innovation is an empirical dynamic placing algorithm\nthat intelligently places requests based on their unique characteristics (e.g.,\nrequest frequency, input data size, and data distribution). In contrast to\nexisting ML systems, StraightLine offers end-to-end resource-aware placement,\nthereby it can significantly reduce response time and failure rate for model\ndeployment when facing different computing resources in the hybrid\ninfrastructure.","Link":"http://arxiv.org/pdf/2407.18148v1","Published":1721923136}
{"Title":"Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI","cs.RO"],"Summary":"Semantic segmentation models are typically trained on a fixed set of classes,\nlimiting their applicability in open-world scenarios. Class-incremental\nsemantic segmentation aims to update models with emerging new classes while\npreventing catastrophic forgetting of previously learned ones. However,\nexisting methods impose strict rigidity on old classes, reducing their\neffectiveness in learning new incremental classes. In this work, we propose\nTaxonomy-Oriented Poincar\\'e-regularized Incremental-Class Segmentation\n(TOPICS) that learns feature embeddings in hyperbolic space following explicit\ntaxonomy-tree structures. This supervision provides plasticity for old classes,\nupdating ancestors based on new classes while integrating new classes at\nfitting positions. Additionally, we maintain implicit class relational\nconstraints on the geometric basis of the Poincar\\'e ball. This ensures that\nthe latent space can continuously adapt to new constraints while maintaining a\nrobust structure to combat catastrophic forgetting. We also establish eight\nrealistic incremental learning protocols for autonomous driving scenarios,\nwhere novel classes can originate from known classes or the background.\nExtensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0\nbenchmarks demonstrate that it achieves state-of-the-art performance. We make\nthe code and trained models publicly available at\nhttp://topics.cs.uni-freiburg.de.","Link":"http://arxiv.org/pdf/2407.18145v1","Published":1721922566}
{"Title":"Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI"],"Summary":"Entropy Regularisation is a widely adopted technique that enhances policy\noptimisation performance and stability. A notable form of entropy\nregularisation is augmenting the objective with an entropy term, thereby\nsimultaneously optimising the expected return and the entropy. This framework,\nknown as maximum entropy reinforcement learning (MaxEnt RL), has shown\ntheoretical and empirical successes. However, its practical application in\nstraightforward on-policy actor-critic settings remains surprisingly\nunderexplored. We hypothesise that this is due to the difficulty of managing\nthe entropy reward in practice. This paper proposes a simple method of\nseparating the entropy objective from the MaxEnt RL objective, which\nfacilitates the implementation of MaxEnt RL in on-policy settings. Our\nempirical evaluations demonstrate that extending Proximal Policy Optimisation\n(PPO) and Trust Region Policy Optimisation (TRPO) within the MaxEnt framework\nimproves policy optimisation performance in both MuJoCo and Procgen tasks.\nAdditionally, our results highlight MaxEnt RL's capacity to enhance\ngeneralisation.","Link":"http://arxiv.org/pdf/2407.18143v1","Published":1721922504}
{"Title":"IRIS: Wireless Ring for Vision-based Smart Home Interaction","Primary Category":"cs.HC","Categories":["cs.HC","cs.ET","cs.LG","eess.IV"],"Summary":"Integrating cameras into wireless smart rings has been challenging due to\nsize and power constraints. We introduce IRIS, the first wireless\nvision-enabled smart ring system for smart home interactions. Equipped with a\ncamera, Bluetooth radio, inertial measurement unit (IMU), and an onboard\nbattery, IRIS meets the small size, weight, and power (SWaP) requirements for\nring devices. IRIS is context-aware, adapting its gesture set to the detected\ndevice, and can last for 16-24 hours on a single charge. IRIS leverages the\nscene semantics to achieve instance-level device recognition. In a study\ninvolving 23 participants, IRIS consistently outpaced voice commands, with a\nhigher proportion of participants expressing a preference for IRIS over voice\ncommands regarding toggling a device's state, granular control, and social\nacceptability. Our work pushes the boundary of what is possible with ring\nform-factor devices, addressing system challenges and opening up novel\ninteraction capabilities.","Link":"http://arxiv.org/pdf/2407.18141v1","Published":1721922317}
{"Title":"Influence Vectors Control for Robots Using Cellular-like Binary Actuators","Primary Category":"cs.RO","Categories":["cs.RO"],"Summary":"Robots using cellular-like redundant binary actuators could outmatch\nelectric-gearmotor robotic systems in terms of reliability, force-to-weight\nratio and cost. This paper presents a robust fault tolerant control scheme that\nis designed to meet the control challenges encountered by such robots, i.e.,\ndiscrete actuator inputs, complex system modeling and cross-coupling between\nactuators. In the proposed scheme, a desired vectorial system output, such as a\nposition or a force, is commanded by recruiting actuators based on their\ninfluence vectors on the output. No analytical model of the system is needed;\ninfluence vectors are identified experimentally by sequentially activating each\nactuator. For position control tasks, the controller uses a probabilistic\napproach and a genetic algorithm to determine an optimal combination of\nactuators to recruit. For motion control tasks, the controller uses a sliding\nmode approach and independent recruiting decision for each actuator.\nExperimental results on a four degrees of freedom binary manipulator with\ntwenty actuators confirm the method's effectiveness, and its ability to\ntolerate massive perturbations and numerous actuator failures.","Link":"http://arxiv.org/pdf/2407.18140v1","Published":1721922246}
{"Title":"$\\mathbb{X}$-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Learning good representations involves capturing the diverse ways in which\ndata samples relate. Contrastive loss - an objective matching related samples -\nunderlies methods from self-supervised to multimodal learning. Contrastive\nlosses, however, can be viewed more broadly as modifying a similarity graph to\nindicate how samples should relate in the embedding space. This view reveals a\nshortcoming in contrastive learning: the similarity graph is binary, as only\none sample is the related positive sample. Crucially, similarities\n\\textit{across} samples are ignored. Based on this observation, we revise the\nstandard contrastive loss to explicitly encode how a sample relates to others.\nWe experiment with this new objective, called $\\mathbb{X}$-Sample Contrastive,\nto train vision models based on similarities in class or text caption\ndescriptions. Our study spans three scales: ImageNet-1k with 1 million, CC3M\nwith 3 million, and CC12M with 12 million samples. The representations learned\nvia our objective outperform both contrastive self-supervised and\nvision-language models trained on the same data across a range of tasks. When\ntraining on CC12M, we outperform CLIP by $0.6\\%$ on both ImageNet and ImageNet\nReal. Our objective appears to work particularly well in lower-data regimes,\nwith gains over CLIP of $16.8\\%$ on ImageNet and $18.1\\%$ on ImageNet Real when\ntraining with CC3M. Finally, our objective seems to encourage the model to\nlearn representations that separate objects from their attributes and\nbackgrounds, with gains of $3.3$-$5.6$\\% over CLIP on ImageNet9. We hope the\nproposed solution takes a small step towards developing richer learning\nobjectives for understanding sample relations in foundation models.","Link":"http://arxiv.org/pdf/2407.18134v1","Published":1721921896}
{"Title":"Estimating Earthquake Magnitude in Sentinel-1 Imagery via Ranking","Primary Category":"cs.CV","Categories":["cs.CV","eess.IV"],"Summary":"Earthquakes are commonly estimated using physical seismic stations, however,\ndue to the installation requirements and costs of these stations, global\ncoverage quickly becomes impractical. An efficient and lower-cost alternative\nis to develop machine learning models to globally monitor earth observation\ndata to pinpoint regions impacted by these natural disasters. However, due to\nthe small amount of historically recorded earthquakes, this becomes a low-data\nregime problem requiring algorithmic improvements to achieve peak performance\nwhen learning to regress earthquake magnitude. In this paper, we propose to\npose the estimation of earthquake magnitudes as a metric-learning problem,\ntraining models to not only estimate earthquake magnitude from Sentinel-1\nsatellite imagery but to additionally rank pairwise samples. Our experiments\nshow at max a 30%+ improvement in MAE over prior regression-only based methods,\nparticularly transformer-based architectures.","Link":"http://arxiv.org/pdf/2407.18128v1","Published":1721921744}
{"Title":"Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI"],"Summary":"In the last few years, deep neural networks have been extensively applied in\nthe medical domain for different tasks, ranging from image classification and\nsegmentation to landmark detection. However, the application of these\ntechnologies in the medical domain is often hindered by data scarcity, both in\nterms of available annotations and images. This study introduces a new\nself-supervised pre-training protocol based on diffusion models for landmark\ndetection in x-ray images. Our results show that the proposed self-supervised\nframework can provide accurate landmark detection with a minimal number of\navailable annotated training images (up to 50), outperforming ImageNet\nsupervised pre-training and state-of-the-art self-supervised pre-trainings for\nthree popular x-ray benchmark datasets. To our knowledge, this is the first\nexploration of diffusion models for self-supervised learning in landmark\ndetection, which may offer a valuable pre-training approach in few-shot\nregimes, for mitigating data scarcity.","Link":"http://arxiv.org/pdf/2407.18125v1","Published":1721921579}
{"Title":"Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI"],"Summary":"In the last few years, deep neural networks have been extensively applied in\nthe medical domain for different tasks, ranging from image classification and\nsegmentation to landmark detection. However, the application of these\ntechnologies in the medical domain is often hindered by data scarcity, both in\nterms of available annotations and images. This study introduces a new\nself-supervised pre-training protocol based on diffusion models for landmark\ndetection in x-ray images. Our results show that the proposed self-supervised\nframework can provide accurate landmark detection with a minimal number of\navailable annotated training images (up to 50), outperforming ImageNet\nsupervised pre-training and state-of-the-art self-supervised pre-trainings for\nthree popular x-ray benchmark datasets. To our knowledge, this is the first\nexploration of diffusion models for self-supervised learning in landmark\ndetection, which may offer a valuable pre-training approach in few-shot\nregimes, for mitigating data scarcity.","Link":"http://arxiv.org/pdf/2407.18125v1","Published":1721921579}
{"Title":"Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI"],"Summary":"In the last few years, deep neural networks have been extensively applied in\nthe medical domain for different tasks, ranging from image classification and\nsegmentation to landmark detection. However, the application of these\ntechnologies in the medical domain is often hindered by data scarcity, both in\nterms of available annotations and images. This study introduces a new\nself-supervised pre-training protocol based on diffusion models for landmark\ndetection in x-ray images. Our results show that the proposed self-supervised\nframework can provide accurate landmark detection with a minimal number of\navailable annotated training images (up to 50), outperforming ImageNet\nsupervised pre-training and state-of-the-art self-supervised pre-trainings for\nthree popular x-ray benchmark datasets. To our knowledge, this is the first\nexploration of diffusion models for self-supervised learning in landmark\ndetection, which may offer a valuable pre-training approach in few-shot\nregimes, for mitigating data scarcity.","Link":"http://arxiv.org/pdf/2407.18125v1","Published":1721921579}
{"Title":"Unsupervised Training of Neural Cellular Automata on Edge Devices","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"The disparity in access to machine learning tools for medical imaging across\ndifferent regions significantly limits the potential for universal healthcare\ninnovation, particularly in remote areas. Our research addresses this issue by\nimplementing Neural Cellular Automata (NCA) training directly on smartphones\nfor accessible X-ray lung segmentation. We confirm the practicality and\nfeasibility of deploying and training these advanced models on five Android\ndevices, improving medical diagnostics accessibility and bridging the tech\ndivide to extend machine learning benefits in medical imaging to low- and\nmiddle-income countries (LMICs). We further enhance this approach with an\nunsupervised adaptation method using the novel Variance-Weighted Segmentation\nLoss (VWSL), which efficiently learns from unlabeled data by minimizing the\nvariance from multiple NCA predictions. This strategy notably improves model\nadaptability and performance across diverse medical imaging contexts without\nthe need for extensive computational resources or labeled datasets, effectively\nlowering the participation threshold. Our methodology, tested on three\nmultisite X-ray datasets -- Padchest, ChestX-ray8, and MIMIC-III --\ndemonstrates improvements in segmentation Dice accuracy by 0.7 to 2.8%,\ncompared to the classic Med-NCA. Additionally, in extreme cases where no\ndigital copy is available and images must be captured by a phone from an X-ray\nlightbox or monitor, VWSL enhances Dice accuracy by 5-20%, demonstrating the\nmethod's robustness even with suboptimal image sources.","Link":"http://arxiv.org/pdf/2407.18114v1","Published":1721920914}
{"Title":"Keypoint Promptable Re-Identification","Primary Category":"cs.CV","Categories":["cs.CV"],"Summary":"Occluded Person Re-Identification (ReID) is a metric learning task that\ninvolves matching occluded individuals based on their appearance. While many\nstudies have tackled occlusions caused by objects, multi-person occlusions\nremain less explored. In this work, we identify and address a critical\nchallenge overlooked by previous occluded ReID methods: the Multi-Person\nAmbiguity (MPA) arising when multiple individuals are visible in the same\nbounding box, making it impossible to determine the intended ReID target among\nthe candidates. Inspired by recent work on prompting in vision, we introduce\nKeypoint Promptable ReID (KPR), a novel formulation of the ReID problem that\nexplicitly complements the input bounding box with a set of semantic keypoints\nindicating the intended target. Since promptable re-identification is an\nunexplored paradigm, existing ReID datasets lack the pixel-level annotations\nnecessary for prompting. To bridge this gap and foster further research on this\ntopic, we introduce Occluded-PoseTrack ReID, a novel ReID dataset with\nkeypoints labels, that features strong inter-person occlusions. Furthermore, we\nrelease custom keypoint labels for four popular ReID benchmarks. Experiments on\nperson retrieval, but also on pose tracking, demonstrate that our method\nsystematically surpasses previous state-of-the-art approaches on various\noccluded scenarios. Our code, dataset and annotations are available at\nhttps://github.com/VlSomers/keypoint_promptable_reidentification.","Link":"http://arxiv.org/pdf/2407.18112v1","Published":1721920858}
{"Title":"MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning","Primary Category":"cs.AR","Categories":["cs.AR","cs.AI"],"Summary":"Technology mapping involves mapping logical circuits to a library of cells.\nTraditionally, the full technology library is used, leading to a large search\nspace and potential overhead. Motivated by randomly sampled technology mapping\ncase studies, we propose MapTune framework that addresses this challenge by\nutilizing reinforcement learning to make design-specific choices during cell\nselection. By learning from the environment, MapTune refines the cell selection\nprocess, resulting in a reduced search space and potentially improved mapping\nquality.\n  The effectiveness of MapTune is evaluated on a wide range of benchmarks,\ndifferent technology libraries and technology mappers. The experimental results\ndemonstrate that MapTune achieves higher mapping accuracy and reducing\ndelay/area across diverse circuit designs, technology libraries and mappers.\nThe paper also discusses the Pareto-Optimal exploration and confirms the\nperpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89,\nITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping and\npost-sizing quality-of-results (QoR) have been significantly improved, with\naverage Area-Delay Product (ADP) improvement of 22.54\\% among all different\nexploration settings in MapTune. The improvements are consistently remained for\nfour different technologies (7nm, 45nm, 130nm, and 180 nm) and two different\nmappers.","Link":"http://arxiv.org/pdf/2407.18110v1","Published":1721920727}
{"Title":"MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning","Primary Category":"cs.AR","Categories":["cs.AR","cs.AI"],"Summary":"Technology mapping involves mapping logical circuits to a library of cells.\nTraditionally, the full technology library is used, leading to a large search\nspace and potential overhead. Motivated by randomly sampled technology mapping\ncase studies, we propose MapTune framework that addresses this challenge by\nutilizing reinforcement learning to make design-specific choices during cell\nselection. By learning from the environment, MapTune refines the cell selection\nprocess, resulting in a reduced search space and potentially improved mapping\nquality.\n  The effectiveness of MapTune is evaluated on a wide range of benchmarks,\ndifferent technology libraries and technology mappers. The experimental results\ndemonstrate that MapTune achieves higher mapping accuracy and reducing\ndelay/area across diverse circuit designs, technology libraries and mappers.\nThe paper also discusses the Pareto-Optimal exploration and confirms the\nperpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89,\nITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping and\npost-sizing quality-of-results (QoR) have been significantly improved, with\naverage Area-Delay Product (ADP) improvement of 22.54\\% among all different\nexploration settings in MapTune. The improvements are consistently remained for\nfour different technologies (7nm, 45nm, 130nm, and 180 nm) and two different\nmappers.","Link":"http://arxiv.org/pdf/2407.18110v1","Published":1721920727}
{"Title":"Graph Neural Ordinary Differential Equations for Coarse-Grained Socioeconomic Dynamics","Primary Category":"cs.LG","Categories":["cs.LG","cs.CY","cs.SI","physics.soc-ph"],"Summary":"We present a data-driven machine-learning approach for modeling space-time\nsocioeconomic dynamics. Through coarse-graining fine-scale observations, our\nmodeling framework simplifies these complex systems to a set of tractable\nmechanistic relationships -- in the form of ordinary differential equations --\nwhile preserving critical system behaviors. This approach allows for expedited\n'what if' studies and sensitivity analyses, essential for informed\npolicy-making. Our findings, from a case study of Baltimore, MD, indicate that\nthis machine learning-augmented coarse-grained model serves as a powerful\ninstrument for deciphering the complex interactions between social factors,\ngeography, and exogenous stressors, offering a valuable asset for system\nforecasting and resilience planning.","Link":"http://arxiv.org/pdf/2407.18108v1","Published":1721920366}
{"Title":"Graph Neural Ordinary Differential Equations for Coarse-Grained Socioeconomic Dynamics","Primary Category":"cs.LG","Categories":["cs.LG","cs.CY","cs.SI","physics.soc-ph"],"Summary":"We present a data-driven machine-learning approach for modeling space-time\nsocioeconomic dynamics. Through coarse-graining fine-scale observations, our\nmodeling framework simplifies these complex systems to a set of tractable\nmechanistic relationships -- in the form of ordinary differential equations --\nwhile preserving critical system behaviors. This approach allows for expedited\n'what if' studies and sensitivity analyses, essential for informed\npolicy-making. Our findings, from a case study of Baltimore, MD, indicate that\nthis machine learning-augmented coarse-grained model serves as a powerful\ninstrument for deciphering the complex interactions between social factors,\ngeography, and exogenous stressors, offering a valuable asset for system\nforecasting and resilience planning.","Link":"http://arxiv.org/pdf/2407.18108v1","Published":1721920366}
{"Title":"Graph Neural Ordinary Differential Equations for Coarse-Grained Socioeconomic Dynamics","Primary Category":"cs.LG","Categories":["cs.LG","cs.CY","cs.SI","physics.soc-ph"],"Summary":"We present a data-driven machine-learning approach for modeling space-time\nsocioeconomic dynamics. Through coarse-graining fine-scale observations, our\nmodeling framework simplifies these complex systems to a set of tractable\nmechanistic relationships -- in the form of ordinary differential equations --\nwhile preserving critical system behaviors. This approach allows for expedited\n'what if' studies and sensitivity analyses, essential for informed\npolicy-making. Our findings, from a case study of Baltimore, MD, indicate that\nthis machine learning-augmented coarse-grained model serves as a powerful\ninstrument for deciphering the complex interactions between social factors,\ngeography, and exogenous stressors, offering a valuable asset for system\nforecasting and resilience planning.","Link":"http://arxiv.org/pdf/2407.18108v1","Published":1721920366}
{"Title":"DINOv2 Rocks Geological Image Analysis: Classification, Segmentation, and Interpretability","Primary Category":"cs.CV","Categories":["cs.CV","physics.geo-ph"],"Summary":"This study investigates the interpretability, classification, and\nsegmentation of CT-scan images of rock samples, with a particular focus on the\napplication of DINOv2 within Geosciences. We compared various segmentation\ntechniques to evaluate their efficacy, efficiency, and adaptability in\ngeological image analysis. The methods assessed include the Otsu thresholding\nmethod, clustering techniques (K-means and fuzzy C-means), a supervised machine\nlearning approach (Random Forest), and deep learning methods (UNet and DINOv2).\nWe tested these methods using ten binary sandstone datasets and three\nmulti-class calcite datasets. To begin, we provide a thorough interpretability\nanalysis of DINOv2's features in the geoscientific context, discussing its\nsuitability and inherent ability to process CT-scanned rock data. In terms of\nclassification, the out-of-the-box DINOv2 demonstrates an impressive capability\nto perfectly classify rock images, even when the CT scans are out of its\noriginal training set. Regarding segmentation, thresholding and unsupervised\nmethods, while fast, perform poorly despite image preprocessing, whereas\nsupervised methods show better results. We underscore the computational demands\nof deep learning but highlight its minimal intervention, superior\ngeneralization, and performance without additional image preprocessing.\nAdditionally, we observe a lack of correlation between a network's depth or the\nnumber of parameters and its performance. Our results show that a LoRA\nfine-tuned DINOv2 excels in out-of-distribution segmentation and significantly\noutperforms other methods in multi-class segmentation. By systematically\ncomparing these methods, we identify the most efficient strategy for meticulous\nand laborious segmentation tasks. DINOv2 proves advantageous, achieving\nsegmentations that could be described as \"better than ground-truth\" against\nrelatively small training sets.","Link":"http://arxiv.org/pdf/2407.18100v1","Published":1721919816}
{"Title":"Unraveling the Web of Disinformation: Exploring the Larger Context of State-Sponsored Influence Campaigns on Twitter","Primary Category":"cs.CY","Categories":["cs.CY","cs.SI"],"Summary":"Social media platforms offer unprecedented opportunities for connectivity and\nexchange of ideas; however, they also serve as fertile grounds for the\ndissemination of disinformation. Over the years, there has been a rise in\nstate-sponsored campaigns aiming to spread disinformation and sway public\nopinion on sensitive topics through designated accounts, known as troll\naccounts. Past works on detecting accounts belonging to state-backed operations\nfocus on a single campaign. While campaign-specific detection techniques are\neasier to build, there is no work done on developing systems that are\ncampaign-agnostic and offer generalized detection of troll accounts unaffected\nby the biases of the specific campaign they belong to. In this paper, we\nidentify several strategies adopted across different state actors and present a\nsystem that leverages them to detect accounts from previously unseen campaigns.\nWe study 19 state-sponsored disinformation campaigns that took place on\nTwitter, originating from various countries. The strategies include sending\nautomated messages through popular scheduling services, retweeting and sharing\nselective content and using fake versions of verified applications for pushing\ncontent. By translating these traits into a feature set, we build a machine\nlearning-based classifier that can correctly identify up to 94% of accounts\nfrom unseen campaigns. Additionally, we run our system in the wild and find\nmore accounts that could potentially belong to state-backed operations. We also\npresent case studies to highlight the similarity between the accounts found by\nour system and those identified by Twitter.","Link":"http://arxiv.org/pdf/2407.18098v1","Published":1721919813}
{"Title":"Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review","Primary Category":"cs.CR","Categories":["cs.CR","cs.AI"],"Summary":"Federated Learning (FL) in the Internet of Things (IoT) environments can\nenhance machine learning by utilising decentralised data, but at the same time,\nit might introduce significant privacy and security concerns due to the\nconstrained nature of IoT devices. This represents a research challenge that we\naim to address in this paper. We systematically analysed recent literature to\nidentify privacy threats in FL within IoT environments, and evaluate the\ndefensive measures that can be employed to mitigate these threats. Using a\nSystematic Literature Review (SLR) approach, we searched five publication\ndatabases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating\nrelevant papers published between 2017 and April 2024, a period which spans\nfrom the introduction of FL until now. Guided by the PRISMA protocol, we\nselected 49 papers to focus our systematic review on. We analysed these papers,\npaying special attention to the privacy threats and defensive measures --\nspecifically within the context of IoT -- using inclusion and exclusion\ncriteria tailored to highlight recent advances and critical insights. We\nidentified various privacy threats, including inference attacks, poisoning\nattacks, and eavesdropping, along with defensive measures such as Differential\nPrivacy and Secure Multi-Party Computation. These defences were evaluated for\ntheir effectiveness in protecting privacy without compromising the functional\nintegrity of FL in IoT settings. Our review underscores the necessity for\nrobust and efficient privacy-preserving strategies tailored for IoT\nenvironments. Notably, there is a need for strategies against replay, evasion,\nand model stealing attacks. Exploring lightweight defensive measures and\nemerging technologies such as blockchain may help improve the privacy of FL in\nIoT, leading to the creation of FL models that can operate under variable\nnetwork conditions.","Link":"http://arxiv.org/pdf/2407.18096v1","Published":1721919716}
{"Title":"Revealing urban area from mobile positioning data","Primary Category":"cs.SI","Categories":["cs.SI","physics.soc-ph"],"Summary":"Researchers face the trade-off between publishing mobility data along with\ntheir papers while simultaneously protecting the privacy of the individuals. In\naddition to the fundamental anonymization process, other techniques, such as\nspatial discretization and, in certain cases, location concealing or complete\nremoval, are applied to achieve these dual objectives. The primary research\nquestion is whether concealing the observation area is an adequate form of\nprotection or whether human mobility patterns in urban areas are inherently\nrevealing of location. The characteristics of the mobility data, such as the\nnumber of activity records or the number of unique users in a given spatial\nunit, reveal the silhouette of the urban landscape, which can be used to infer\nthe identity of the city in question. It was demonstrated that even without\ndisclosing the exact location, the patterns of human mobility can still reveal\nthe urban area from which the data was collected. The presented locating method\nwas tested on other cities using different open data sets and against coarser\nspatial discretization units. While publishing mobility data is essential for\nresearch, it was demonstrated that concealing the observation area is\ninsufficient to prevent the identification of the urban area. Furthermore,\nusing larger discretization units alone is an ineffective solution to the\nproblem of the observation area re-identification. Instead of obscuring the\nobservation area, noise should be added to the trajectories to prevent user\nidentification.","Link":"http://arxiv.org/pdf/2407.18086v1","Published":1721918952}
{"Title":"Revealing urban area from mobile positioning data","Primary Category":"cs.SI","Categories":["cs.SI","physics.soc-ph"],"Summary":"Researchers face the trade-off between publishing mobility data along with\ntheir papers while simultaneously protecting the privacy of the individuals. In\naddition to the fundamental anonymization process, other techniques, such as\nspatial discretization and, in certain cases, location concealing or complete\nremoval, are applied to achieve these dual objectives. The primary research\nquestion is whether concealing the observation area is an adequate form of\nprotection or whether human mobility patterns in urban areas are inherently\nrevealing of location. The characteristics of the mobility data, such as the\nnumber of activity records or the number of unique users in a given spatial\nunit, reveal the silhouette of the urban landscape, which can be used to infer\nthe identity of the city in question. It was demonstrated that even without\ndisclosing the exact location, the patterns of human mobility can still reveal\nthe urban area from which the data was collected. The presented locating method\nwas tested on other cities using different open data sets and against coarser\nspatial discretization units. While publishing mobility data is essential for\nresearch, it was demonstrated that concealing the observation area is\ninsufficient to prevent the identification of the urban area. Furthermore,\nusing larger discretization units alone is an ineffective solution to the\nproblem of the observation area re-identification. Instead of obscuring the\nobservation area, noise should be added to the trajectories to prevent user\nidentification.","Link":"http://arxiv.org/pdf/2407.18086v1","Published":1721918952}
{"Title":"Revealing urban area from mobile positioning data","Primary Category":"cs.SI","Categories":["cs.SI","physics.soc-ph"],"Summary":"Researchers face the trade-off between publishing mobility data along with\ntheir papers while simultaneously protecting the privacy of the individuals. In\naddition to the fundamental anonymization process, other techniques, such as\nspatial discretization and, in certain cases, location concealing or complete\nremoval, are applied to achieve these dual objectives. The primary research\nquestion is whether concealing the observation area is an adequate form of\nprotection or whether human mobility patterns in urban areas are inherently\nrevealing of location. The characteristics of the mobility data, such as the\nnumber of activity records or the number of unique users in a given spatial\nunit, reveal the silhouette of the urban landscape, which can be used to infer\nthe identity of the city in question. It was demonstrated that even without\ndisclosing the exact location, the patterns of human mobility can still reveal\nthe urban area from which the data was collected. The presented locating method\nwas tested on other cities using different open data sets and against coarser\nspatial discretization units. While publishing mobility data is essential for\nresearch, it was demonstrated that concealing the observation area is\ninsufficient to prevent the identification of the urban area. Furthermore,\nusing larger discretization units alone is an ineffective solution to the\nproblem of the observation area re-identification. Instead of obscuring the\nobservation area, noise should be added to the trajectories to prevent user\nidentification.","Link":"http://arxiv.org/pdf/2407.18086v1","Published":1721918952}
{"Title":"Principal-Agent Reinforcement Learning","Primary Category":"cs.GT","Categories":["cs.GT","cs.LG","cs.MA"],"Summary":"Contracts are the economic framework which allows a principal to delegate a\ntask to an agent -- despite misaligned interests, and even without directly\nobserving the agent's actions. In many modern reinforcement learning settings,\nself-interested agents learn to perform a multi-stage task delegated to them by\na principal. We explore the significant potential of utilizing contracts to\nincentivize the agents. We model the delegated task as an MDP, and study a\nstochastic game between the principal and agent where the principal learns what\ncontracts to use, and the agent learns an MDP policy in response. We present a\nlearning-based algorithm for optimizing the principal's contracts, which\nprovably converges to the subgame-perfect equilibrium of the principal-agent\ngame. A deep RL implementation allows us to apply our method to very large MDPs\nwith unknown transition dynamics. We extend our approach to multiple agents,\nand demonstrate its relevance to resolving a canonical sequential social\ndilemma with minimal intervention to agent rewards.","Link":"http://arxiv.org/pdf/2407.18074v1","Published":1721917738}
{"Title":"Principal-Agent Reinforcement Learning","Primary Category":"cs.GT","Categories":["cs.GT","cs.LG","cs.MA"],"Summary":"Contracts are the economic framework which allows a principal to delegate a\ntask to an agent -- despite misaligned interests, and even without directly\nobserving the agent's actions. In many modern reinforcement learning settings,\nself-interested agents learn to perform a multi-stage task delegated to them by\na principal. We explore the significant potential of utilizing contracts to\nincentivize the agents. We model the delegated task as an MDP, and study a\nstochastic game between the principal and agent where the principal learns what\ncontracts to use, and the agent learns an MDP policy in response. We present a\nlearning-based algorithm for optimizing the principal's contracts, which\nprovably converges to the subgame-perfect equilibrium of the principal-agent\ngame. A deep RL implementation allows us to apply our method to very large MDPs\nwith unknown transition dynamics. We extend our approach to multiple agents,\nand demonstrate its relevance to resolving a canonical sequential social\ndilemma with minimal intervention to agent rewards.","Link":"http://arxiv.org/pdf/2407.18074v1","Published":1721917738}
{"Title":"C2P: Featuring Large Language Models with Causal Reasoning","Primary Category":"cs.LO","Categories":["cs.LO"],"Summary":"Causal reasoning is the primary bottleneck that Large Language Models (LLMs)\nmust overcome to attain human-level intelligence. To address this, we introduce\nthe Causal Chain of Prompting (C2P) as the first reasoning framework that\nequips current LLMs with causal reasoning capabilities. C2P operates\nautonomously, avoiding reliance on external tools or modules during both the\ncausal learning and reasoning phases, and can be seamlessly implemented during\nthe training or fine-tuning of LLMs. Experimental results across various\nbenchmark datasets demonstrate a significant improvement in causal learning and\nsubsequent reasoning accuracy of LLMs. We illustrate how C2P enhances LLMs'\nability to causally reason in real-world scenarios, addressing complex problems\nin fields such as healthcare, medicine, economics, education, social sciences,\nenvironmental science, and marketing. With few-shot learning, GPT-4 Turbo using\nC2P with as few as six examples achieves significant performance improvements,\nboasting over a 33% increase in reasoning accuracy over the most\nstate-of-the-art LLMs, which perform nearly randomly in similar circumstances.\nThis demonstrates the transformative potential of integrating C2P into LLM\ntraining or fine-tuning processes, thereby empowering these models with\nadvanced causal reasoning capabilities.","Link":"http://arxiv.org/pdf/2407.18069v1","Published":1721917497}
{"Title":"HVM-1: Large-scale video models pretrained with nearly 5000 hours of human-like video data","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG","cs.NE","q-bio.NC"],"Summary":"We introduce Human-like Video Models (HVM-1), large-scale video models\npretrained with nearly 5000 hours of curated human-like video data (mostly\negocentric, temporally extended, continuous video recordings), using the\nspatiotemporal masked autoencoder (ST-MAE) algorithm. We release two 633M\nparameter models trained at spatial resolutions of 224x224 and 448x448 pixels.\nWe evaluate the performance of these models in downstream few-shot video and\nimage recognition tasks and compare them against a model pretrained with 1330\nhours of short action-oriented video clips from YouTube (Kinetics-700). HVM-1\nmodels perform competitively against the Kinetics-700 pretrained model in\ndownstream evaluations despite substantial qualitative differences between the\nspatiotemporal characteristics of the corresponding pretraining datasets. HVM-1\nmodels also learn more accurate and more robust object representations compared\nto models pretrained with the image-based MAE algorithm on the same data,\ndemonstrating the potential benefits of learning to predict temporal\nregularities in natural videos for learning better object representations.","Link":"http://arxiv.org/pdf/2407.18067v1","Published":1721917310}
{"Title":"Multi-Agent Deep Reinforcement Learning for Resilience Optimization in 5G RAN","Primary Category":"cs.LG","Categories":["cs.LG","cs.NI"],"Summary":"Resilience is defined as the ability of a network to resist, adapt, and\nquickly recover from disruptions, and to continue to maintain an acceptable\nlevel of services from users' perspective. With the advent of future radio\nnetworks, including advanced 5G and upcoming 6G, critical services become\nintegral to future networks, requiring uninterrupted service delivery for end\nusers. Unfortunately, with the growing network complexity, user mobility and\ndiversity, it becomes challenging to scale current resilience management\ntechniques that rely on local optimizations to large dense network deployments.\nThis paper aims to address this problem by globally optimizing the resilience\nof a dense multi-cell network based on multi-agent deep reinforcement learning.\nSpecifically, our proposed solution can dynamically tilt cell antennas and\nreconfigure transmit power to mitigate outages and increase both coverage and\nservice availability. A multi-objective optimization problem is formulated to\nsimultaneously satisfy resiliency constraints while maximizing the service\nquality in the network area in order to minimize the impact of outages on\nneighbouring cells. Extensive simulations then demonstrate that with our\nproposed solution, the average service availability in terms of user throughput\ncan be increased by up to 50-60% on average, while reaching a coverage\navailability of 99% in best cases.","Link":"http://arxiv.org/pdf/2407.18066v1","Published":1721917199}
{"Title":"Difficulty Estimation and Simplification of French Text Using LLMs","Primary Category":"cs.CL","Categories":["cs.CL","cs.AI"],"Summary":"We leverage generative large language models for language learning\napplications, focusing on estimating the difficulty of foreign language texts\nand simplifying them to lower difficulty levels. We frame both tasks as\nprediction problems and develop a difficulty classification model using labeled\nexamples, transfer learning, and large language models, demonstrating superior\naccuracy compared to previous approaches. For simplification, we evaluate the\ntrade-off between simplification quality and meaning preservation, comparing\nzero-shot and fine-tuned performances of large language models. We show that\nmeaningful text simplifications can be obtained with limited fine-tuning. Our\nexperiments are conducted on French texts, but our methods are\nlanguage-agnostic and directly applicable to other foreign languages.","Link":"http://arxiv.org/pdf/2407.18061v1","Published":1721916968}
{"Title":"Cross-Vendor Reproducibility of Radiomics-based Machine Learning Models for Computer-aided Diagnosis","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Background: The reproducibility of machine-learning models in prostate cancer\ndetection across different MRI vendors remains a significant challenge.\nMethods: This study investigates Support Vector Machines (SVM) and Random\nForest (RF) models trained on radiomic features extracted from T2-weighted MRI\nimages using Pyradiomics and MRCradiomics libraries. Feature selection was\nperformed using the maximum relevance minimum redundancy (MRMR) technique. We\naimed to enhance clinical decision support through multimodal learning and\nfeature fusion. Results: Our SVM model, utilizing combined features from\nPyradiomics and MRCradiomics, achieved an AUC of 0.74 on the Multi-Improd\ndataset (Siemens scanner) but decreased to 0.60 on the Philips test set. The RF\nmodel showed similar trends, with notable robustness for models using\nPyradiomics features alone (AUC of 0.78 on Philips). Conclusions: These\nfindings demonstrate the potential of multimodal feature integration to improve\nthe robustness and generalizability of machine-learning models for clinical\ndecision support in prostate cancer detection. This study marks a significant\nstep towards developing reliable AI-driven diagnostic tools that maintain\nefficacy across various imaging platforms.","Link":"http://arxiv.org/pdf/2407.18060v1","Published":1721916962}
{"Title":"I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition","Primary Category":"cs.SD","Categories":["cs.SD","cs.CL","cs.IR","cs.LG","eess.AS"],"Summary":"Music two-tower multimodal systems integrate audio and text modalities into a\njoint audio-text space, enabling direct comparison between songs and their\ncorresponding labels. These systems enable new approaches for classification\nand retrieval, leveraging both modalities. Despite the promising results they\nhave shown for zero-shot classification and retrieval tasks, closer inspection\nof the embeddings is needed. This paper evaluates the inherent zero-shot\nproperties of joint audio-text spaces for the case-study of instrument\nrecognition. We present an evaluation and analysis of two-tower systems for\nzero-shot instrument recognition and a detailed analysis of the properties of\nthe pre-joint and joint embeddings spaces. Our findings suggest that audio\nencoders alone demonstrate good quality, while challenges remain within the\ntext encoder or joint space projection. Specifically, two-tower systems exhibit\nsensitivity towards specific words, favoring generic prompts over musically\ninformed ones. Despite the large size of textual encoders, they do not yet\nleverage additional textual context or infer instruments accurately from their\ndescriptions. Lastly, a novel approach for quantifying the semantic\nmeaningfulness of the textual space leveraging an instrument ontology is\nproposed. This method reveals deficiencies in the systems' understanding of\ninstruments and provides evidence of the need for fine-tuning text encoders on\nmusical data.","Link":"http://arxiv.org/pdf/2407.18058v1","Published":1721916905}
{"Title":"I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition","Primary Category":"cs.SD","Categories":["cs.SD","cs.CL","cs.IR","cs.LG","eess.AS"],"Summary":"Music two-tower multimodal systems integrate audio and text modalities into a\njoint audio-text space, enabling direct comparison between songs and their\ncorresponding labels. These systems enable new approaches for classification\nand retrieval, leveraging both modalities. Despite the promising results they\nhave shown for zero-shot classification and retrieval tasks, closer inspection\nof the embeddings is needed. This paper evaluates the inherent zero-shot\nproperties of joint audio-text spaces for the case-study of instrument\nrecognition. We present an evaluation and analysis of two-tower systems for\nzero-shot instrument recognition and a detailed analysis of the properties of\nthe pre-joint and joint embeddings spaces. Our findings suggest that audio\nencoders alone demonstrate good quality, while challenges remain within the\ntext encoder or joint space projection. Specifically, two-tower systems exhibit\nsensitivity towards specific words, favoring generic prompts over musically\ninformed ones. Despite the large size of textual encoders, they do not yet\nleverage additional textual context or infer instruments accurately from their\ndescriptions. Lastly, a novel approach for quantifying the semantic\nmeaningfulness of the textual space leveraging an instrument ontology is\nproposed. This method reveals deficiencies in the systems' understanding of\ninstruments and provides evidence of the need for fine-tuning text encoders on\nmusical data.","Link":"http://arxiv.org/pdf/2407.18058v1","Published":1721916905}
{"Title":"GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI"],"Summary":"Implicit neural representations (INRs) have significantly advanced the field\nof arbitrary-scale super-resolution (ASSR) of images. Most existing INR-based\nASSR networks first extract features from the given low-resolution image using\nan encoder, and then render the super-resolved result via a multi-layer\nperceptron decoder. Although these approaches have shown promising results,\ntheir performance is constrained by the limited representation ability of\ndiscrete latent codes in the encoded features. In this paper, we propose a\nnovel ASSR method named GaussianSR that overcomes this limitation through 2D\nGaussian Splatting (2DGS). Unlike traditional methods that treat pixels as\ndiscrete points, GaussianSR represents each pixel as a continuous Gaussian\nfield. The encoded features are simultaneously refined and upsampled by\nrendering the mutually stacked Gaussian fields. As a result, long-range\ndependencies are established to enhance representation ability. In addition, a\nclassifier is developed to dynamically assign Gaussian kernels to all pixels to\nfurther improve flexibility. All components of GaussianSR (i.e., encoder,\nclassifier, Gaussian kernels, and decoder) are jointly learned end-to-end.\nExperiments demonstrate that GaussianSR achieves superior ASSR performance with\nfewer parameters than existing methods while enjoying interpretable and\ncontent-aware feature aggregations.","Link":"http://arxiv.org/pdf/2407.18046v1","Published":1721915628}
{"Title":"The Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Digital health chatbots powered by Large Language Models (LLMs) have the\npotential to significantly improve personal health management for chronic\nconditions by providing accessible and on-demand health coaching and\nquestion-answering. However, these chatbots risk providing unverified and\ninaccurate information because LLMs generate responses based on patterns\nlearned from diverse internet data. Retrieval Augmented Generation (RAG) can\nhelp mitigate hallucinations and inaccuracies in LLM responses by grounding it\non reliable content. However, efficiently and accurately retrieving most\nrelevant set of content for real-time user questions remains a challenge. In\nthis work, we introduce Query-Based Retrieval Augmented Generation (QB-RAG), a\nnovel approach that pre-computes a database of potential queries from a content\nbase using LLMs. For an incoming patient question, QB-RAG efficiently matches\nit against this pre-generated query database using vector search, improving\nalignment between user questions and the content. We establish a theoretical\nfoundation for QB-RAG and provide a comparative analysis of existing retrieval\nenhancement techniques for RAG systems. Finally, our empirical evaluation\ndemonstrates that QB-RAG significantly improves the accuracy of healthcare\nquestion answering, paving the way for robust and trustworthy LLM applications\nin digital health.","Link":"http://arxiv.org/pdf/2407.18044v1","Published":1721915221}
{"Title":"Lifelong Graph Summarization with Neural Networks: 2012, 2022, and a Time Warp","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Summarizing web graphs is challenging due to the heterogeneity of the modeled\ninformation and its changes over time. We investigate the use of neural\nnetworks for lifelong graph summarization. Assuming we observe the web graph at\na certain time, we train the networks to summarize graph vertices. We apply\nthis trained network to summarize the vertices of the changed graph at the next\npoint in time. Subsequently, we continue training and evaluating the network to\nperform lifelong graph summarization. We use the GNNs Graph-MLP and GraphSAINT,\nas well as an MLP baseline, to summarize the temporal graphs. We compare\n$1$-hop and $2$-hop summaries. We investigate the impact of reusing parameters\nfrom a previous snapshot by measuring the backward and forward transfer and the\nforgetting rate of the neural networks. Our extensive experiments on ten weekly\nsnapshots of a web graph with over $100$M edges, sampled in 2012 and 2022, show\nthat all networks predominantly use $1$-hop information to determine the\nsummary, even when performing $2$-hop summarization. Due to the heterogeneity\nof web graphs, in some snapshots, the $2$-hop summary produces over ten times\nmore vertex summaries than the $1$-hop summary. When using the network trained\non the last snapshot from 2012 and applying it to the first snapshot of 2022,\nwe observe a strong drop in accuracy. We attribute this drop over the ten-year\ntime warp to the strongly increased heterogeneity of the web graph in 2022.","Link":"http://arxiv.org/pdf/2407.18042v1","Published":1721915082}
{"Title":"How to Train the Teacher Model for Effective Knowledge Distillation","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Recently, it was shown that the role of the teacher in knowledge distillation\n(KD) is to provide the student with an estimate of the true Bayes conditional\nprobability density (BCPD). Notably, the new findings propose that the\nstudent's error rate can be upper-bounded by the mean squared error (MSE)\nbetween the teacher's output and BCPD. Consequently, to enhance KD efficacy,\nthe teacher should be trained such that its output is close to BCPD in MSE\nsense. This paper elucidates that training the teacher model with MSE loss\nequates to minimizing the MSE between its output and BCPD, aligning with its\ncore responsibility of providing the student with a BCPD estimate closely\nresembling it in MSE terms. In this respect, through a comprehensive set of\nexperiments, we demonstrate that substituting the conventional teacher trained\nwith cross-entropy loss with one trained using MSE loss in state-of-the-art KD\nmethods consistently boosts the student's accuracy, resulting in improvements\nof up to 2.6\\%.","Link":"http://arxiv.org/pdf/2407.18041v1","Published":1721914751}
{"Title":"Peak-Controlled Logits Poisoning Attack in Federated Distillation","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI"],"Summary":"Federated Distillation (FD) offers an innovative approach to distributed\nmachine learning, leveraging knowledge distillation for efficient and flexible\ncross-device knowledge transfer without necessitating the upload of extensive\nmodel parameters to a central server. While FD has gained popularity, its\nvulnerability to poisoning attacks remains underexplored. To address this gap,\nwe previously introduced FDLA (Federated Distillation Logits Attack), a method\nthat manipulates logits communication to mislead and degrade the performance of\nclient models. However, the impact of FDLA on participants with different\nidentities and the effects of malicious modifications at various stages of\nknowledge transfer remain unexplored. To this end, we present PCFDLA\n(Peak-Controlled Federated Distillation Logits Attack), an advanced and more\nstealthy logits poisoning attack method for FD. PCFDLA enhances the\neffectiveness of FDLA by carefully controlling the peak values of logits to\ncreate highly misleading yet inconspicuous modifications. Furthermore, we\nintroduce a novel metric for better evaluating attack efficacy, demonstrating\nthat PCFDLA maintains stealth while being significantly more disruptive to\nvictim models compared to its predecessors. Experimental results across various\ndatasets confirm the superior impact of PCFDLA on model accuracy, solidifying\nits potential threat in federated distillation systems.","Link":"http://arxiv.org/pdf/2407.18039v1","Published":1721914602}
{"Title":"TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo Matching within A Joint Learning Framework","Primary Category":"cs.CV","Categories":["cs.CV","cs.RO"],"Summary":"Semantic segmentation and stereo matching, respectively analogous to the\nventral and dorsal streams in our human brain, are two key components of\nautonomous driving perception systems. Addressing these two tasks with separate\nnetworks is no longer the mainstream direction in developing computer vision\nalgorithms, particularly with the recent advances in large vision models and\nembodied artificial intelligence. The trend is shifting towards combining them\nwithin a joint learning framework, especially emphasizing feature sharing\nbetween the two tasks. The major contributions of this study lie in\ncomprehensively tightening the coupling between semantic segmentation and\nstereo matching. Specifically, this study introduces three novelties: (1) a\ntightly coupled, gated feature fusion strategy, (2) a hierarchical deep\nsupervision strategy, and (3) a coupling tightening loss function. The combined\nuse of these technical contributions results in TiCoSS, a state-of-the-art\njoint learning framework that simultaneously tackles semantic segmentation and\nstereo matching. Through extensive experiments on the KITTI and vKITTI2\ndatasets, along with qualitative and quantitative analyses, we validate the\neffectiveness of our developed strategies and loss function, and demonstrate\nits superior performance compared to prior arts, with a notable increase in\nmIoU by over 9%. Our source code will be publicly available at\nmias.group/TiCoSS upon publication.","Link":"http://arxiv.org/pdf/2407.18038v1","Published":1721914315}
{"Title":"TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo Matching within A Joint Learning Framework","Primary Category":"cs.CV","Categories":["cs.CV","cs.RO"],"Summary":"Semantic segmentation and stereo matching, respectively analogous to the\nventral and dorsal streams in our human brain, are two key components of\nautonomous driving perception systems. Addressing these two tasks with separate\nnetworks is no longer the mainstream direction in developing computer vision\nalgorithms, particularly with the recent advances in large vision models and\nembodied artificial intelligence. The trend is shifting towards combining them\nwithin a joint learning framework, especially emphasizing feature sharing\nbetween the two tasks. The major contributions of this study lie in\ncomprehensively tightening the coupling between semantic segmentation and\nstereo matching. Specifically, this study introduces three novelties: (1) a\ntightly coupled, gated feature fusion strategy, (2) a hierarchical deep\nsupervision strategy, and (3) a coupling tightening loss function. The combined\nuse of these technical contributions results in TiCoSS, a state-of-the-art\njoint learning framework that simultaneously tackles semantic segmentation and\nstereo matching. Through extensive experiments on the KITTI and vKITTI2\ndatasets, along with qualitative and quantitative analyses, we validate the\neffectiveness of our developed strategies and loss function, and demonstrate\nits superior performance compared to prior arts, with a notable increase in\nmIoU by over 9%. Our source code will be publicly available at\nmias.group/TiCoSS upon publication.","Link":"http://arxiv.org/pdf/2407.18038v1","Published":1721914315}
{"Title":"ECG Arrhythmia Detection Using Disease-specific Attention-based Deep Learning Model","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"The electrocardiogram (ECG) is one of the most commonly-used tools to\ndiagnose cardiovascular disease in clinical practice. Although deep learning\nmodels have achieved very impressive success in the field of automatic ECG\nanalysis, they often lack model interpretability that is significantly\nimportant in the healthcare applications. To this end, many schemes such as\ngeneral-purpose attention mechanism, Grad-CAM technique and ECG knowledge graph\nwere proposed to be integrated with deep learning models. However, they either\nresult in decreased classification performance or do not consist with the one\nin cardiologists' mind when interpreting ECG. In this study, we propose a novel\ndisease-specific attention-based deep learning model (DANet) for arrhythmia\ndetection from short ECG recordings. The novel idea is to introduce a\nsoft-coding or hard-coding waveform enhanced module into existing deep neural\nnetworks, which amends original ECG signals with the guidance of the rule for\ndiagnosis of a given disease type before being fed into the classification\nmodule. For the soft-coding DANet, we also develop a learning framework\ncombining self-supervised pre-training with two-stage supervised training. To\nverify the effectiveness of our proposed DANet, we applied it to the problem of\natrial premature contraction detection and the experimental results shows that\nit demonstrates superior performance compared to the benchmark model. Moreover,\nit also provides the waveform regions that deserve special attention in the\nmodel's decision-making process, allowing it to be a medical diagnostic\nassistant for physicians.","Link":"http://arxiv.org/pdf/2407.18033v1","Published":1721914030}
{"Title":"$k$-Center Clustering in Distributed Models","Primary Category":"cs.DC","Categories":["cs.DC","cs.DS"],"Summary":"The $k$-center problem is a central optimization problem with numerous\napplications for machine learning, data mining, and communication networks.\nDespite extensive study in various scenarios, it surprisingly has not been\nthoroughly explored in the traditional distributed setting, where the\ncommunication graph of a network also defines the distance metric.\n  We initiate the study of the $k$-center problem in a setting where the\nunderlying metric is the graph's shortest path metric in three canonical\ndistributed settings: the LOCAL, CONGEST, and CLIQUE models. Our results\nencompass constant-factor approximation algorithms and lower bounds in these\nmodels, as well as hardness results for the bi-criteria approximation setting.","Link":"http://arxiv.org/pdf/2407.18031v1","Published":1721914019}
{"Title":"$k$-Center Clustering in Distributed Models","Primary Category":"cs.DC","Categories":["cs.DC","cs.DS"],"Summary":"The $k$-center problem is a central optimization problem with numerous\napplications for machine learning, data mining, and communication networks.\nDespite extensive study in various scenarios, it surprisingly has not been\nthoroughly explored in the traditional distributed setting, where the\ncommunication graph of a network also defines the distance metric.\n  We initiate the study of the $k$-center problem in a setting where the\nunderlying metric is the graph's shortest path metric in three canonical\ndistributed settings: the LOCAL, CONGEST, and CLIQUE models. Our results\nencompass constant-factor approximation algorithms and lower bounds in these\nmodels, as well as hardness results for the bi-criteria approximation setting.","Link":"http://arxiv.org/pdf/2407.18031v1","Published":1721914019}
{"Title":"Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind","Primary Category":"cs.NE","Categories":["cs.NE","cs.AI","cs.LG","cs.RO"],"Summary":"Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental\nstates to others, is a crucial feature of human social interaction. In complex\nenvironments, where the human sensory system reaches its limits, behaviour is\nstrongly driven by our beliefs about the state of the world around us.\nAccessing others' mental states, e.g., beliefs and intentions, allows for more\neffective social interactions in natural contexts. Yet, these variables are not\ndirectly observable, making understanding ToM a challenging quest of interest\nfor different fields, including psychology, machine learning and robotics. In\nthis paper, we contribute to this topic by showing a developmental synergy\nbetween learning to predict low-level mental states (e.g., intentions, goals)\nand attributing high-level ones (i.e., beliefs). Specifically, we assume that\nlearning beliefs attribution can occur by observing one's own decision\nprocesses involving beliefs, e.g., in a partially observable environment. Using\na simple feed-forward deep learning model, we show that, when learning to\npredict others' intentions and actions, more accurate predictions can be\nacquired earlier if beliefs attribution is learnt simultaneously. Furthermore,\nwe show that the learning performance improves even when observed actors have a\ndifferent embodiment than the observer and the gain is higher when observing\nbeliefs-driven chunks of behaviour. We propose that our computational approach\ncan inform the understanding of human social cognitive development and be\nrelevant for the design of future adaptive social robots able to autonomously\nunderstand, assist, and learn from human interaction partners in novel natural\nenvironments and tasks.","Link":"http://arxiv.org/pdf/2407.18022v1","Published":1721913325}
{"Title":"Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind","Primary Category":"cs.NE","Categories":["cs.NE","cs.AI","cs.LG","cs.RO"],"Summary":"Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental\nstates to others, is a crucial feature of human social interaction. In complex\nenvironments, where the human sensory system reaches its limits, behaviour is\nstrongly driven by our beliefs about the state of the world around us.\nAccessing others' mental states, e.g., beliefs and intentions, allows for more\neffective social interactions in natural contexts. Yet, these variables are not\ndirectly observable, making understanding ToM a challenging quest of interest\nfor different fields, including psychology, machine learning and robotics. In\nthis paper, we contribute to this topic by showing a developmental synergy\nbetween learning to predict low-level mental states (e.g., intentions, goals)\nand attributing high-level ones (i.e., beliefs). Specifically, we assume that\nlearning beliefs attribution can occur by observing one's own decision\nprocesses involving beliefs, e.g., in a partially observable environment. Using\na simple feed-forward deep learning model, we show that, when learning to\npredict others' intentions and actions, more accurate predictions can be\nacquired earlier if beliefs attribution is learnt simultaneously. Furthermore,\nwe show that the learning performance improves even when observed actors have a\ndifferent embodiment than the observer and the gain is higher when observing\nbeliefs-driven chunks of behaviour. We propose that our computational approach\ncan inform the understanding of human social cognitive development and be\nrelevant for the design of future adaptive social robots able to autonomously\nunderstand, assist, and learn from human interaction partners in novel natural\nenvironments and tasks.","Link":"http://arxiv.org/pdf/2407.18022v1","Published":1721913325}
{"Title":"Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind","Primary Category":"cs.NE","Categories":["cs.NE","cs.AI","cs.LG","cs.RO"],"Summary":"Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental\nstates to others, is a crucial feature of human social interaction. In complex\nenvironments, where the human sensory system reaches its limits, behaviour is\nstrongly driven by our beliefs about the state of the world around us.\nAccessing others' mental states, e.g., beliefs and intentions, allows for more\neffective social interactions in natural contexts. Yet, these variables are not\ndirectly observable, making understanding ToM a challenging quest of interest\nfor different fields, including psychology, machine learning and robotics. In\nthis paper, we contribute to this topic by showing a developmental synergy\nbetween learning to predict low-level mental states (e.g., intentions, goals)\nand attributing high-level ones (i.e., beliefs). Specifically, we assume that\nlearning beliefs attribution can occur by observing one's own decision\nprocesses involving beliefs, e.g., in a partially observable environment. Using\na simple feed-forward deep learning model, we show that, when learning to\npredict others' intentions and actions, more accurate predictions can be\nacquired earlier if beliefs attribution is learnt simultaneously. Furthermore,\nwe show that the learning performance improves even when observed actors have a\ndifferent embodiment than the observer and the gain is higher when observing\nbeliefs-driven chunks of behaviour. We propose that our computational approach\ncan inform the understanding of human social cognitive development and be\nrelevant for the design of future adaptive social robots able to autonomously\nunderstand, assist, and learn from human interaction partners in novel natural\nenvironments and tasks.","Link":"http://arxiv.org/pdf/2407.18022v1","Published":1721913325}
{"Title":"Self-Supervision Improves Diffusion Models for Tabular Data Imputation","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"The ubiquity of missing data has sparked considerable attention and focus on\ntabular data imputation methods. Diffusion models, recognized as the\ncutting-edge technique for data generation, demonstrate significant potential\nin tabular data imputation tasks. However, in pursuit of diversity, vanilla\ndiffusion models often exhibit sensitivity to initialized noises, which hinders\nthe models from generating stable and accurate imputation results.\nAdditionally, the sparsity inherent in tabular data poses challenges for\ndiffusion models in accurately modeling the data manifold, impacting the\nrobustness of these models for data imputation. To tackle these challenges,\nthis paper introduces an advanced diffusion model named Self-supervised\nimputation Diffusion Model (SimpDM for brevity), specifically tailored for\ntabular data imputation tasks. To mitigate sensitivity to noise, we introduce a\nself-supervised alignment mechanism that aims to regularize the model, ensuring\nconsistent and stable imputation predictions. Furthermore, we introduce a\ncarefully devised state-dependent data augmentation strategy within SimpDM,\nenhancing the robustness of the diffusion model when dealing with limited data.\nExtensive experiments demonstrate that SimpDM matches or outperforms\nstate-of-the-art imputation methods across various scenarios.","Link":"http://arxiv.org/pdf/2407.18013v1","Published":1721912790}
{"Title":"HANNA: Hard-constraint Neural Network for Consistent Activity Coefficient Prediction","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"We present the first hard-constraint neural network for predicting activity\ncoefficients (HANNA), a thermodynamic mixture property that is the basis for\nmany applications in science and engineering. Unlike traditional neural\nnetworks, which ignore physical laws and result in inconsistent predictions,\nour model is designed to strictly adhere to all thermodynamic consistency\ncriteria. By leveraging deep-set neural networks, HANNA maintains symmetry\nunder the permutation of the components. Furthermore, by hard-coding physical\nconstraints in the network architecture, we ensure consistency with the\nGibbs-Duhem equation and in modeling the pure components. The model was trained\nand evaluated on 317,421 data points for activity coefficients in binary\nmixtures from the Dortmund Data Bank, achieving significantly higher prediction\naccuracies than the current state-of-the-art model UNIFAC. Moreover, HANNA only\nrequires the SMILES of the components as input, making it applicable to any\nbinary mixture of interest. HANNA is fully open-source and available for free\nuse.","Link":"http://arxiv.org/pdf/2407.18011v1","Published":1721912700}
{"Title":"GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy","Primary Category":"cs.CY","Categories":["cs.CY","cs.CL","K.4"],"Summary":"LLMs are changing the way humans create and interact with content,\npotentially affecting citizens' political opinions and voting decisions. As\nLLMs increasingly shape our digital information ecosystems, auditing to\nevaluate biases, sycophancy, or steerability has emerged as an active field of\nresearch. In this paper, we evaluate and compare the alignment of six LLMs by\nOpenAI, Anthropic, and Cohere with German party positions and evaluate\nsycophancy based on a prompt experiment. We contribute to evaluating political\nbias and sycophancy in multi-party systems across major commercial LLMs. First,\nwe develop the benchmark dataset GermanPartiesQA based on the Voting Advice\nApplication Wahl-o-Mat covering 10 state and 1 national elections between 2021\nand 2023. In our study, we find a left-green tendency across all examined LLMs.\nWe then conduct our prompt experiment for which we use the benchmark and\nsociodemographic data of leading German parliamentarians to evaluate changes in\nLLMs responses. To differentiate between sycophancy and steerabilty, we use 'I\nam [politician X], ...' and 'You are [politician X], ...' prompts. Against our\nexpectations, we do not observe notable differences between prompting 'I am'\nand 'You are'. While our findings underscore that LLM responses can be\nideologically steered with political personas, they suggest that observed\nchanges in LLM outputs could be better described as personalization to the\ngiven context rather than sycophancy.","Link":"http://arxiv.org/pdf/2407.18008v1","Published":1721912665}
{"Title":"The Existential Theory of the Reals as a Complexity Class: A Compendium","Primary Category":"cs.CC","Categories":["cs.CC","cs.CG","cs.DS","cs.FL","cs.LO"],"Summary":"We survey the complexity class $\\exists \\mathbb{R}$, which captures the\ncomplexity of deciding the existential theory of the reals. The class $\\exists\n\\mathbb{R}$ has roots in two different traditions, one based on the\nBlum-Shub-Smale model of real computation, and the other following work by\nMn\\\"{e}v and Shor on the universality of realization spaces of oriented\nmatroids. Over the years the number of problems for which $\\exists \\mathbb{R}$\nrather than NP has turned out to be the proper way of measuring their\ncomplexity has grown, particularly in the fields of computational geometry,\ngraph drawing, game theory, and some areas in logic and algebra. $\\exists\n\\mathbb{R}$ has also started appearing in the context of machine learning,\nMarkov decision processes, and probabilistic reasoning.\n  We have aimed at collecting a comprehensive compendium of problems complete\nand hard for $\\exists \\mathbb{R}$, as well as a long list of open problems. The\ncompendium is presented in the third part of our survey; a tour through the\ncompendium and the areas it touches on makes up the second part. The first part\nintroduces the reader to the existential theory of the reals as a complexity\nclass, discussing its history, motivation and prospects as well as some\ntechnical aspects.","Link":"http://arxiv.org/pdf/2407.18006v1","Published":1721912526}
{"Title":"Network Inversion of Convolutional Neural Nets","Primary Category":"cs.LG","Categories":["cs.LG","cs.CV"],"Summary":"Neural networks have emerged as powerful tools across various applications,\nyet their decision-making process often remains opaque, leading to them being\nperceived as \"black boxes.\" This opacity raises concerns about their\ninterpretability and reliability, especially in safety-critical scenarios.\nNetwork inversion techniques offer a solution by allowing us to peek inside\nthese black boxes, revealing the features and patterns learned by the networks\nbehind their decision-making processes and thereby provide valuable insights\ninto how neural networks arrive at their conclusions, making them more\ninterpretable and trustworthy. This paper presents a simple yet effective\napproach to network inversion using a carefully conditioned generator that\nlearns the data distribution in the input space of the trained neural network,\nenabling the reconstruction of inputs that would most likely lead to the\ndesired outputs. To capture the diversity in the input space for a given\noutput, instead of simply revealing the conditioning labels to the generator,\nwe hideously encode the conditioning label information into vectors, further\nexemplified by heavy dropout in the generation process and minimisation of\ncosine similarity between the features corresponding to the generated images.\nThe paper concludes with immediate applications of Network Inversion including\nin interpretability, explainability and generation of adversarial samples.","Link":"http://arxiv.org/pdf/2407.18002v1","Published":1721912001}
{"Title":"Lightweight Industrial Cohorted Federated Learning for Heterogeneous Assets","Primary Category":"cs.LG","Categories":["cs.LG","eess.SP"],"Summary":"Federated Learning (FL) is the most widely adopted collaborative learning\napproach for training decentralized Machine Learning (ML) models by exchanging\nlearning between clients without sharing the data and compromising privacy.\nHowever, since great data similarity or homogeneity is taken for granted in all\nFL tasks, FL is still not specifically designed for the industrial setting.\nRarely this is the case in industrial data because there are differences in\nmachine type, firmware version, operational conditions, environmental factors,\nand hence, data distribution. Albeit its popularity, it has been observed that\nFL performance degrades if the clients have heterogeneous data distributions.\nTherefore, we propose a Lightweight Industrial Cohorted FL (LICFL) algorithm\nthat uses model parameters for cohorting without any additional on-edge\n(clientlevel) computations and communications than standard FL and mitigates\nthe shortcomings from data heterogeneity in industrial applications. Our\napproach enhances client-level model performance by allowing them to\ncollaborate with similar clients and train more specialized or personalized\nmodels. Also, we propose an adaptive aggregation algorithm that extends the\nLICFL to Adaptive LICFL (ALICFL) for further improving the global model\nperformance and speeding up the convergence. Through numerical experiments on\nreal-time data, we demonstrate the efficacy of the proposed algorithms and\ncompare the performance with existing approaches.","Link":"http://arxiv.org/pdf/2407.17999v1","Published":1721911736}
{"Title":"iNNspector: Visual, Interactive Deep Model Debugging","Primary Category":"cs.HC","Categories":["cs.HC","cs.LG"],"Summary":"Deep learning model design, development, and debugging is a process driven by\nbest practices, guidelines, trial-and-error, and the personal experiences of\nmodel developers. At multiple stages of this process, performance and internal\nmodel data can be logged and made available. However, due to the sheer\ncomplexity and scale of this data and process, model developers often resort to\nevaluating their model performance based on abstract metrics like accuracy and\nloss. We argue that a structured analysis of data along the model's\narchitecture and at multiple abstraction levels can considerably streamline the\ndebugging process. Such a systematic analysis can further connect the\ndeveloper's design choices to their impacts on the model behavior, facilitating\nthe understanding, diagnosis, and refinement of deep learning models. Hence, in\nthis paper, we (1) contribute a conceptual framework structuring the data space\nof deep learning experiments. Our framework, grounded in literature analysis\nand requirements interviews, captures design dimensions and proposes mechanisms\nto make this data explorable and tractable. To operationalize our framework in\na ready-to-use application, we (2) present the iNNspector system. iNNspector\nenables tracking of deep learning experiments and provides interactive\nvisualizations of the data on all levels of abstraction from multiple models to\nindividual neurons. Finally, we (3) evaluate our approach with three real-world\nuse-cases and a user study with deep learning developers and data analysts,\nproving its effectiveness and usability.","Link":"http://arxiv.org/pdf/2407.17998v1","Published":1721911721}
{"Title":"On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures","Primary Category":"cs.CL","Categories":["cs.CL","cs.LG","cs.SD","eess.AS"],"Summary":"In this work we evaluate the utility of synthetic data for training automatic\nspeech recognition (ASR). We use the ASR training data to train a\ntext-to-speech (TTS) system similar to FastSpeech-2. With this TTS we reproduce\nthe original training data, training ASR systems solely on synthetic data. For\nASR, we use three different architectures, attention-based encoder-decoder,\nhybrid deep neural network hidden Markov model and a Gaussian mixture hidden\nMarkov model, showing the different sensitivity of the models to synthetic data\ngeneration. In order to extend previous work, we present a number of ablation\nstudies on the effectiveness of synthetic vs. real training data for ASR. In\nparticular we focus on how the gap between training on synthetic and real data\nchanges by varying the speaker embedding or by scaling the model size. For the\nlatter we show that the TTS models generalize well, even when training scores\nindicate overfitting.","Link":"http://arxiv.org/pdf/2407.17997v1","Published":1721911485}
{"Title":"Joint RGB-Spectral Decomposition Model Guided Image Enhancement in Mobile Photography","Primary Category":"cs.CV","Categories":["cs.CV"],"Summary":"The integration of miniaturized spectrometers into mobile devices offers new\navenues for image quality enhancement and facilitates novel downstream tasks.\nHowever, the broader application of spectral sensors in mobile photography is\nhindered by the inherent complexity of spectral images and the constraints of\nspectral imaging capabilities. To overcome these challenges, we propose a joint\nRGB-Spectral decomposition model guided enhancement framework, which consists\nof two steps: joint decomposition and prior-guided enhancement. Firstly, we\nleverage the complementarity between RGB and Low-resolution Multi-Spectral\nImages (Lr-MSI) to predict shading, reflectance, and material semantic priors.\nSubsequently, these priors are seamlessly integrated into the established\nHDRNet to promote dynamic range enhancement, color mapping, and grid expert\nlearning, respectively. Additionally, we construct a high-quality Mobile-Spec\ndataset to support our research, and our experiments validate the effectiveness\nof Lr-MSI in the tone enhancement task. This work aims to establish a solid\nfoundation for advancing spectral vision in mobile photography. The code is\navailable at \\url{https://github.com/CalayZhou/JDM-HDRNet}.","Link":"http://arxiv.org/pdf/2407.17996v1","Published":1721911421}
{"Title":"Discursive Patinas: Anchoring Discussions in Data Visualizations","Primary Category":"cs.HC","Categories":["cs.HC"],"Summary":"This paper presents discursive patinas, a technique to visualize discussions\nonto data visualizations, inspired by how people leave traces in the physical\nworld. While data visualizations are widely discussed in online communities and\nsocial media, comments tend to be displayed separately from the visualization\nand we lack ways to relate these discussions back to the content of the\nvisualization, e.g., to situate comments, explain visual patterns, or question\nassumptions. In our visualization annotation interface, users can designate\nareas within the visualization. Discursive patinas are made of overlaid visual\nmarks (anchors), attached to textual comments with category labels, likes, and\nreplies. By coloring and styling the anchors, a meta visualization emerges,\nshowing what and where people comment and annotate the visualization. These\npatinas show regions of heavy discussions, recent commenting activity, and the\ndistribution of questions, suggestions, or personal stories. We ran workshops\nwith 90 students, domain experts, and visualization researchers to study how\npeople use anchors to discuss visualizations and how patinas influence people's\nunderstanding of the discussion. Our results show that discursive patinas\nimprove the ability to navigate discussions and guide people to comments that\nhelp understand, contextualize, or scrutinize the visualization. We discuss the\npotential of anchors and patinas to support discursive engagements, including\ncritical readings of visualizations, design feedback, and feminist approaches\nto data visualization.","Link":"http://arxiv.org/pdf/2407.17994v1","Published":1721911220}
{"Title":"Amortized Active Learning for Nonparametric Functions","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Active learning (AL) is a sequential learning scheme aiming to select the\nmost informative data. AL reduces data consumption and avoids the cost of\nlabeling large amounts of data. However, AL trains the model and solves an\nacquisition optimization for each selection. It becomes expensive when the\nmodel training or acquisition optimization is challenging. In this paper, we\nfocus on active nonparametric function learning, where the gold standard\nGaussian process (GP) approaches suffer from cubic time complexity. We propose\nan amortized AL method, where new data are suggested by a neural network which\nis trained up-front without any real data (Figure 1). Our method avoids\nrepeated model training and requires no acquisition optimization during the AL\ndeployment. We (i) utilize GPs as function priors to construct an AL simulator,\n(ii) train an AL policy that can zero-shot generalize from simulation to real\nlearning problems of nonparametric functions and (iii) achieve real-time data\nselection and comparable learning performances to time-consuming baseline\nmethods.","Link":"http://arxiv.org/pdf/2407.17992v1","Published":1721911088}
{"Title":"Amortized Active Learning for Nonparametric Functions","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Active learning (AL) is a sequential learning scheme aiming to select the\nmost informative data. AL reduces data consumption and avoids the cost of\nlabeling large amounts of data. However, AL trains the model and solves an\nacquisition optimization for each selection. It becomes expensive when the\nmodel training or acquisition optimization is challenging. In this paper, we\nfocus on active nonparametric function learning, where the gold standard\nGaussian process (GP) approaches suffer from cubic time complexity. We propose\nan amortized AL method, where new data are suggested by a neural network which\nis trained up-front without any real data (Figure 1). Our method avoids\nrepeated model training and requires no acquisition optimization during the AL\ndeployment. We (i) utilize GPs as function priors to construct an AL simulator,\n(ii) train an AL policy that can zero-shot generalize from simulation to real\nlearning problems of nonparametric functions and (iii) achieve real-time data\nselection and comparable learning performances to time-consuming baseline\nmethods.","Link":"http://arxiv.org/pdf/2407.17992v1","Published":1721911088}
{"Title":"Amortized Active Learning for Nonparametric Functions","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Active learning (AL) is a sequential learning scheme aiming to select the\nmost informative data. AL reduces data consumption and avoids the cost of\nlabeling large amounts of data. However, AL trains the model and solves an\nacquisition optimization for each selection. It becomes expensive when the\nmodel training or acquisition optimization is challenging. In this paper, we\nfocus on active nonparametric function learning, where the gold standard\nGaussian process (GP) approaches suffer from cubic time complexity. We propose\nan amortized AL method, where new data are suggested by a neural network which\nis trained up-front without any real data (Figure 1). Our method avoids\nrepeated model training and requires no acquisition optimization during the AL\ndeployment. We (i) utilize GPs as function priors to construct an AL simulator,\n(ii) train an AL policy that can zero-shot generalize from simulation to real\nlearning problems of nonparametric functions and (iii) achieve real-time data\nselection and comparable learning performances to time-consuming baseline\nmethods.","Link":"http://arxiv.org/pdf/2407.17992v1","Published":1721911088}
{"Title":"Personalized and Context-aware Route Planning for Edge-assisted Vehicles","Primary Category":"cs.AI","Categories":["cs.AI","cs.RO"],"Summary":"Conventional route planning services typically offer the same routes to all\ndrivers, focusing primarily on a few standardized factors such as travel\ndistance or time, overlooking individual driver preferences. With the inception\nof autonomous vehicles expected in the coming years, where vehicles will rely\non routes decided by such planners, there arises a need to incorporate the\nspecific preferences of each driver, ensuring personalized navigation\nexperiences. In this work, we propose a novel approach based on graph neural\nnetworks (GNNs) and deep reinforcement learning (DRL), aimed at customizing\nroutes to suit individual preferences. By analyzing the historical trajectories\nof individual drivers, we classify their driving behavior and associate it with\nrelevant road attributes as indicators of driver preferences. The GNN is\ncapable of representing the road network as graph-structured data effectively,\nwhile DRL is capable of making decisions utilizing reward mechanisms to\noptimize route selection with factors such as travel costs, congestion level,\nand driver satisfaction. We evaluate our proposed GNN-based DRL framework using\na real-world road network and demonstrate its ability to accommodate driver\npreferences, offering a range of route options tailored to individual drivers.\nThe results indicate that our framework can select routes that accommodate\ndriver's preferences with up to a 17% improvement compared to a generic route\nplanner, and reduce the travel time by 33% (afternoon) and 46% (evening)\nrelatively to the shortest distance-based approach.","Link":"http://arxiv.org/pdf/2407.17980v1","Published":1721909652}
{"Title":"What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models","Primary Category":"cs.CL","Categories":["cs.CL"],"Summary":"Humans have clear cross-modal preferences when matching certain novel words\nto visual shapes. Evidence suggests that these preferences play a prominent\nrole in our linguistic processing, language learning, and the origins of\nsignal-meaning mappings. With the rise of multimodal models in AI, such as\nvision- and-language (VLM) models, it becomes increasingly important to uncover\nthe kinds of visio-linguistic associations these models encode and whether they\nalign with human representations. Informed by experiments with humans, we probe\nand compare four VLMs for a well-known human cross-modal preference, the\nbouba-kiki effect. We do not find conclusive evidence for this effect but\nsuggest that results may depend on features of the models, such as architecture\ndesign, model size, and training details. Our findings inform discussions on\nthe origins of the bouba-kiki effect in human cognition and future developments\nof VLMs that align well with human cross-modal associations.","Link":"http://arxiv.org/pdf/2407.17974v1","Published":1721909381}
{"Title":"Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI"],"Summary":"Large language models (LLMs) have demonstrated impressive versatility across\nnumerous tasks, yet their generalization capabilities remain poorly understood.\nTo investigate these behaviors, arithmetic tasks serve as important venues. In\nprevious studies, seemingly unrelated mysteries still exist -- (1) models with\nappropriate positional embeddings can correctly perform longer unseen\narithmetic operations such as addition, but their effectiveness varies in more\ncomplex tasks like multiplication; (2) models perform well for longer unseen\ncases in modular addition under specific moduli (e.g., modulo 100) but struggle\nunder very close moduli (e.g., modulo 101), regardless of the positional\nencoding used. We believe previous studies have been treating the symptoms\nrather than addressing the root cause -- they have paid excessive attention to\nimproving model components, while overlooking the differences in task\nproperties that may be the real drivers. This is confirmed by our unified\ntheoretical framework for different arithmetic scenarios. For example, unlike\nmultiplication, the digital addition task has the property of translation\ninvariance which naturally aligns with the relative positional encoding, and\nthis combination leads to successful generalization of addition to unseen\nlonger domains. The discrepancy in operations modulo 100 and 101 arises from\nthe base. Modulo 100, unlike 101, is compatible with the decimal system (base\n10), such that unseen information in digits beyond the units digit and the tens\ndigit is actually not needed for the task. Extensive experiments with GPT-like\nmodels validate our theoretical predictions. These findings deepen our\nunderstanding of the generalization mechanisms, and facilitate more\ndata-efficient model training and objective-oriented AI alignment.","Link":"http://arxiv.org/pdf/2407.17963v1","Published":1721907322}
{"Title":"Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI"],"Summary":"Large language models (LLMs) have demonstrated impressive versatility across\nnumerous tasks, yet their generalization capabilities remain poorly understood.\nTo investigate these behaviors, arithmetic tasks serve as important venues. In\nprevious studies, seemingly unrelated mysteries still exist -- (1) models with\nappropriate positional embeddings can correctly perform longer unseen\narithmetic operations such as addition, but their effectiveness varies in more\ncomplex tasks like multiplication; (2) models perform well for longer unseen\ncases in modular addition under specific moduli (e.g., modulo 100) but struggle\nunder very close moduli (e.g., modulo 101), regardless of the positional\nencoding used. We believe previous studies have been treating the symptoms\nrather than addressing the root cause -- they have paid excessive attention to\nimproving model components, while overlooking the differences in task\nproperties that may be the real drivers. This is confirmed by our unified\ntheoretical framework for different arithmetic scenarios. For example, unlike\nmultiplication, the digital addition task has the property of translation\ninvariance which naturally aligns with the relative positional encoding, and\nthis combination leads to successful generalization of addition to unseen\nlonger domains. The discrepancy in operations modulo 100 and 101 arises from\nthe base. Modulo 100, unlike 101, is compatible with the decimal system (base\n10), such that unseen information in digits beyond the units digit and the tens\ndigit is actually not needed for the task. Extensive experiments with GPT-like\nmodels validate our theoretical predictions. These findings deepen our\nunderstanding of the generalization mechanisms, and facilitate more\ndata-efficient model training and objective-oriented AI alignment.","Link":"http://arxiv.org/pdf/2407.17963v1","Published":1721907322}
{"Title":"Neural Networks for Generating Better Local Optima in Topology Optimization","Primary Category":"cs.LG","Categories":["cs.LG"],"Summary":"Neural networks have recently been employed as material discretizations\nwithin adjoint optimization frameworks for inverse problems and topology\noptimization. While advantageous regularization effects and better optima have\nbeen found for some inverse problems, the benefit for topology optimization has\nbeen limited -- where the focus of investigations has been the compliance\nproblem. We demonstrate how neural network material discretizations can, under\ncertain conditions, find better local optima in more challenging optimization\nproblems, where we here specifically consider acoustic topology optimization.\nThe chances of identifying a better optimum can significantly be improved by\nrunning multiple partial optimizations with different neural network\ninitializations. Furthermore, we show that the neural network material\ndiscretization's advantage comes from the interplay with the Adam optimizer and\nemphasize its current limitations when competing with constrained and\nhigher-order optimization techniques. At the moment, this discretization has\nonly been shown to be beneficial for unconstrained first-order optimization.","Link":"http://arxiv.org/pdf/2407.17957v1","Published":1721906684}
{"Title":"SaccadeDet: A Novel Dual-Stage Architecture for Rapid and Accurate Detection in Gigapixel Images","Primary Category":"cs.CV","Categories":["cs.CV"],"Summary":"The advancement of deep learning in object detection has predominantly\nfocused on megapixel images, leaving a critical gap in the efficient processing\nof gigapixel images. These super high-resolution images present unique\nchallenges due to their immense size and computational demands. To address\nthis, we introduce 'SaccadeDet', an innovative architecture for gigapixel-level\nobject detection, inspired by the human eye saccadic movement. The cornerstone\nof SaccadeDet is its ability to strategically select and process image regions,\ndramatically reducing computational load. This is achieved through a two-stage\nprocess: the 'saccade' stage, which identifies regions of probable interest,\nand the 'gaze' stage, which refines detection in these targeted areas. Our\napproach, evaluated on the PANDA dataset, not only achieves an 8x speed\nincrease over the state-of-the-art methods but also demonstrates significant\npotential in gigapixel-level pathology analysis through its application to\nWhole Slide Imaging.","Link":"http://arxiv.org/pdf/2407.17956v1","Published":1721906574}
{"Title":"Scaling Training Data with Lossy Image Compression","Primary Category":"cs.CV","Categories":["cs.CV","cs.IT","cs.LG","math.IT"],"Summary":"Empirically-determined scaling laws have been broadly successful in\npredicting the evolution of large machine learning models with training data\nand number of parameters. As a consequence, they have been useful for\noptimizing the allocation of limited resources, most notably compute time.\n  In certain applications, storage space is an important constraint, and data\nformat needs to be chosen carefully as a consequence. Computer vision is a\nprominent example: images are inherently analog, but are always stored in a\ndigital format using a finite number of bits. Given a dataset of digital\nimages, the number of bits $L$ to store each of them can be further reduced\nusing lossy data compression. This, however, can degrade the quality of the\nmodel trained on such images, since each example has lower resolution.\n  In order to capture this trade-off and optimize storage of training data, we\npropose a `storage scaling law' that describes the joint evolution of test\nerror with sample size and number of bits per image. We prove that this law\nholds within a stylized model for image compression, and verify it empirically\non two computer vision tasks, extracting the relevant parameters. We then show\nthat this law can be used to optimize the lossy compression level. At given\nstorage, models trained on optimally compressed images present a significantly\nsmaller test error with respect to models trained on the original data.\nFinally, we investigate the potential benefits of randomizing the compression\nlevel.","Link":"http://arxiv.org/pdf/2407.17954v1","Published":1721906395}
{"Title":"BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular Depth Estimation","Primary Category":"cs.CV","Categories":["cs.CV"],"Summary":"By training over large-scale datasets, zero-shot monocular depth estimation\n(MDE) methods show robust performance in the wild but often suffer from\ninsufficiently precise details. Although recent diffusion-based MDE approaches\nexhibit appealing detail extraction ability, they still struggle in\ngeometrically challenging scenes due to the difficulty of gaining robust\ngeometric priors from diverse datasets. To leverage the complementary merits of\nboth worlds, we propose BetterDepth to efficiently achieve geometrically\ncorrect affine-invariant MDE performance while capturing fine-grained details.\nSpecifically, BetterDepth is a conditional diffusion-based refiner that takes\nthe prediction from pre-trained MDE models as depth conditioning, in which the\nglobal depth context is well-captured, and iteratively refines details based on\nthe input image. For the training of such a refiner, we propose global\npre-alignment and local patch masking methods to ensure the faithfulness of\nBetterDepth to depth conditioning while learning to capture fine-grained scene\ndetails. By efficient training on small-scale synthetic datasets, BetterDepth\nachieves state-of-the-art zero-shot MDE performance on diverse public datasets\nand in-the-wild scenes. Moreover, BetterDepth can improve the performance of\nother MDE models in a plug-and-play manner without additional re-training.","Link":"http://arxiv.org/pdf/2407.17952v1","Published":1721906197}
{"Title":"Real Time American Sign Language Detection Using Yolo-v9","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI","cs.LG"],"Summary":"This paper focuses on real-time American Sign Language Detection. YOLO is a\nconvolutional neural network (CNN) based model, which was first released in\n2015. In recent years, it gained popularity for its real-time detection\ncapabilities. Our study specifically targets YOLO-v9 model, released in 2024.\nAs the model is newly introduced, not much work has been done on it, especially\nnot in Sign Language Detection. Our paper provides deep insight on how YOLO- v9\nworks and better than previous model.","Link":"http://arxiv.org/pdf/2407.17950v1","Published":1721905865}
{"Title":"Real Time American Sign Language Detection Using Yolo-v9","Primary Category":"cs.CV","Categories":["cs.CV","cs.AI","cs.LG"],"Summary":"This paper focuses on real-time American Sign Language Detection. YOLO is a\nconvolutional neural network (CNN) based model, which was first released in\n2015. In recent years, it gained popularity for its real-time detection\ncapabilities. Our study specifically targets YOLO-v9 model, released in 2024.\nAs the model is newly introduced, not much work has been done on it, especially\nnot in Sign Language Detection. Our paper provides deep insight on how YOLO- v9\nworks and better than previous model.","Link":"http://arxiv.org/pdf/2407.17950v1","Published":1721905865}
{"Title":"Comparison of different Artificial Neural Networks for Bitcoin price forecasting","Primary Category":"cs.LG","Categories":["cs.LG","cs.AI"],"Summary":"This study investigates the impact of varying sequence lengths on the\naccuracy of predicting cryptocurrency returns using Artificial Neural Networks\n(ANNs). Utilizing the Mean Absolute Error (MAE) as a threshold criterion, we\naim to enhance prediction accuracy by excluding returns that are smaller than\nthis threshold, thus mitigating errors associated with minor returns. The\nsubsequent evaluation focuses on the accuracy of predicted returns that exceed\nthis threshold. We compare four sequence lengths 168 hours (7 days), 72 hours\n(3 days), 24 hours, and 12 hours each with a return prediction interval of 2\nhours. Our findings reveal the influence of sequence length on prediction\naccuracy and underscore the potential for optimized sequence configurations in\nfinancial forecasting models.","Link":"http://arxiv.org/pdf/2407.17930v1","Published":1721903990}
{"Title":"Guided Latent Slot Diffusion for Object-Centric Learning","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Slot attention aims to decompose an input image into a set of meaningful\nobject files (slots). These latent object representations enable various\ndownstream tasks. Yet, these slots often bind to object parts, not objects\nthemselves, especially for real-world datasets. To address this, we introduce\nGuided Latent Slot Diffusion - GLASS, an object-centric model that uses\ngenerated captions as a guiding signal to better align slots with objects. Our\nkey insight is to learn the slot-attention module in the space of generated\nimages. This allows us to repurpose the pre-trained diffusion decoder model,\nwhich reconstructs the images from the slots, as a semantic mask generator\nbased on the generated captions. GLASS learns an object-level representation\nsuitable for multiple tasks simultaneously, e.g., segmentation, image\ngeneration, and property prediction, outperforming previous methods. For object\ndiscovery, GLASS achieves approx. a +35% and +10% relative improvement for mIoU\nover the previous state-of-the-art (SOTA) method on the VOC and COCO datasets,\nrespectively, and establishes a new SOTA FID score for conditional image\ngeneration amongst slot-attention-based methods. For the segmentation task,\nGLASS surpasses SOTA weakly-supervised and language-based segmentation models,\nwhich were specifically designed for the task.","Link":"http://arxiv.org/pdf/2407.17929v1","Published":1721903912}
{"Title":"Guided Latent Slot Diffusion for Object-Centric Learning","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Slot attention aims to decompose an input image into a set of meaningful\nobject files (slots). These latent object representations enable various\ndownstream tasks. Yet, these slots often bind to object parts, not objects\nthemselves, especially for real-world datasets. To address this, we introduce\nGuided Latent Slot Diffusion - GLASS, an object-centric model that uses\ngenerated captions as a guiding signal to better align slots with objects. Our\nkey insight is to learn the slot-attention module in the space of generated\nimages. This allows us to repurpose the pre-trained diffusion decoder model,\nwhich reconstructs the images from the slots, as a semantic mask generator\nbased on the generated captions. GLASS learns an object-level representation\nsuitable for multiple tasks simultaneously, e.g., segmentation, image\ngeneration, and property prediction, outperforming previous methods. For object\ndiscovery, GLASS achieves approx. a +35% and +10% relative improvement for mIoU\nover the previous state-of-the-art (SOTA) method on the VOC and COCO datasets,\nrespectively, and establishes a new SOTA FID score for conditional image\ngeneration amongst slot-attention-based methods. For the segmentation task,\nGLASS surpasses SOTA weakly-supervised and language-based segmentation models,\nwhich were specifically designed for the task.","Link":"http://arxiv.org/pdf/2407.17929v1","Published":1721903912}
{"Title":"Guided Latent Slot Diffusion for Object-Centric Learning","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Slot attention aims to decompose an input image into a set of meaningful\nobject files (slots). These latent object representations enable various\ndownstream tasks. Yet, these slots often bind to object parts, not objects\nthemselves, especially for real-world datasets. To address this, we introduce\nGuided Latent Slot Diffusion - GLASS, an object-centric model that uses\ngenerated captions as a guiding signal to better align slots with objects. Our\nkey insight is to learn the slot-attention module in the space of generated\nimages. This allows us to repurpose the pre-trained diffusion decoder model,\nwhich reconstructs the images from the slots, as a semantic mask generator\nbased on the generated captions. GLASS learns an object-level representation\nsuitable for multiple tasks simultaneously, e.g., segmentation, image\ngeneration, and property prediction, outperforming previous methods. For object\ndiscovery, GLASS achieves approx. a +35% and +10% relative improvement for mIoU\nover the previous state-of-the-art (SOTA) method on the VOC and COCO datasets,\nrespectively, and establishes a new SOTA FID score for conditional image\ngeneration amongst slot-attention-based methods. For the segmentation task,\nGLASS surpasses SOTA weakly-supervised and language-based segmentation models,\nwhich were specifically designed for the task.","Link":"http://arxiv.org/pdf/2407.17929v1","Published":1721903912}
{"Title":"Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models","Primary Category":"cs.CL","Categories":["cs.CL"],"Summary":"Representations from deep neural networks (DNNs) have proven remarkably\npredictive of neural activity involved in both visual and linguistic\nprocessing. Despite these successes, most studies to date concern unimodal\nDNNs, encoding either visual or textual input but not both. Yet, there is\ngrowing evidence that human meaning representations integrate linguistic and\nsensory-motor information. Here we investigate whether the integration of\nmultimodal information operated by current vision-and-language DNN models\n(VLMs) leads to representations that are more aligned with human brain activity\nthan those obtained by language-only and vision-only DNNs. We focus on fMRI\nresponses recorded while participants read concept words in the context of\neither a full sentence or an accompanying picture. Our results reveal that VLM\nrepresentations correlate more strongly than language- and vision-only DNNs\nwith activations in brain areas functionally related to language processing. A\ncomparison between different types of visuo-linguistic architectures shows that\nrecent generative VLMs tend to be less brain-aligned than previous\narchitectures with lower performance on downstream applications. Moreover,\nthrough an additional analysis comparing brain vs. behavioural alignment across\nmultiple VLMs, we show that -- with one remarkable exception -- representations\nthat strongly align with behavioural judgments do not correlate highly with\nbrain responses. This indicates that brain similarity does not go hand in hand\nwith behavioural similarity, and vice versa.","Link":"http://arxiv.org/pdf/2407.17914v1","Published":1721902117}
{"Title":"Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models","Primary Category":"cs.CL","Categories":["cs.CL"],"Summary":"Representations from deep neural networks (DNNs) have proven remarkably\npredictive of neural activity involved in both visual and linguistic\nprocessing. Despite these successes, most studies to date concern unimodal\nDNNs, encoding either visual or textual input but not both. Yet, there is\ngrowing evidence that human meaning representations integrate linguistic and\nsensory-motor information. Here we investigate whether the integration of\nmultimodal information operated by current vision-and-language DNN models\n(VLMs) leads to representations that are more aligned with human brain activity\nthan those obtained by language-only and vision-only DNNs. We focus on fMRI\nresponses recorded while participants read concept words in the context of\neither a full sentence or an accompanying picture. Our results reveal that VLM\nrepresentations correlate more strongly than language- and vision-only DNNs\nwith activations in brain areas functionally related to language processing. A\ncomparison between different types of visuo-linguistic architectures shows that\nrecent generative VLMs tend to be less brain-aligned than previous\narchitectures with lower performance on downstream applications. Moreover,\nthrough an additional analysis comparing brain vs. behavioural alignment across\nmultiple VLMs, we show that -- with one remarkable exception -- representations\nthat strongly align with behavioural judgments do not correlate highly with\nbrain responses. This indicates that brain similarity does not go hand in hand\nwith behavioural similarity, and vice versa.","Link":"http://arxiv.org/pdf/2407.17914v1","Published":1721902117}
{"Title":"Separating Novel Features for Logical Anomaly Detection: A Straightforward yet Effective Approach","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"Vision-based inspection algorithms have significantly contributed to quality\ncontrol in industrial settings, particularly in addressing structural defects\nlike dent and contamination which are prevalent in mass production. Extensive\nresearch efforts have led to the development of related benchmarks such as\nMVTec AD (Bergmann et al., 2019). However, in industrial settings, there can be\ninstances of logical defects, where acceptable items are found in unsuitable\nlocations or product pairs do not match as expected. Recent methods tackling\nlogical defects effectively employ knowledge distillation to generate\ndifference maps. Knowledge distillation (KD) is used to learn normal data\ndistribution in unsupervised manner. Despite their effectiveness, these methods\noften overlook the potential false negatives. Excessive similarity between the\nteacher network and student network can hinder the generation of a suitable\ndifference map for logical anomaly detection. This technical report provides\ninsights on handling potential false negatives by utilizing a simple constraint\nin KD-based logical anomaly detection methods. We select EfficientAD as a\nstate-of-the-art baseline and apply a margin-based constraint to its\nunsupervised learning scheme. Applying this constraint, we can improve the\nAUROC for MVTec LOCO AD by 1.3 %.","Link":"http://arxiv.org/pdf/2407.17909v1","Published":1721901621}
{"Title":"Amortized Posterior Sampling with Diffusion Prior Distillation","Primary Category":"cs.CV","Categories":["cs.CV","cs.LG"],"Summary":"We propose a variational inference approach to sample from the posterior\ndistribution for solving inverse problems. From a pre-trained diffusion model,\nour approach trains a conditional flow model to minimize the divergence between\nthe proposal variational distribution and the posterior distribution implicitly\ndefined through the diffusion model. Once trained, the flow model is capable of\nsampling from the posterior distribution with a single NFE, amortized with\nrespect to the measurement. The proposed method paves a new path for distilling\na diffusion prior for efficient posterior sampling. We show that our method is\napplicable to standard signals in Euclidean space, as well as signals on\nmanifold.","Link":"http://arxiv.org/pdf/2407.17907v1","Published":1721901192}
{"Title":"Hierarchical Object Detection and Recognition Framework for Practical Plant Disease Diagnosis","Primary Category":"cs.CV","Categories":["cs.CV"],"Summary":"Recently, object detection methods (OD; e.g., YOLO-based models) have been\nwidely utilized in plant disease diagnosis. These methods demonstrate\nrobustness to distance variations and excel at detecting small lesions compared\nto classification methods (CL; e.g., CNN models). However, there are issues\nsuch as low diagnostic performance for hard-to-detect diseases and high\nlabeling costs. Additionally, since healthy cases cannot be explicitly trained,\nthere is a risk of false positives. We propose the Hierarchical object\ndetection and recognition framework (HODRF), a sophisticated and highly\nintegrated two-stage system that combines the strengths of both OD and CL for\nplant disease diagnosis. In the first stage, HODRF uses OD to identify regions\nof interest (ROIs) without specifying the disease. In the second stage, CL\ndiagnoses diseases surrounding the ROIs. HODRF offers several advantages: (1)\nSince OD detects only one type of ROI, HODRF can detect diseases with limited\ntraining images by leveraging its ability to identify other lesions. (2) While\nOD over-detects healthy cases, HODRF significantly reduces these errors by\nusing CL in the second stage. (3) CL's accuracy improves in HODRF as it\nidentifies diagnostic targets given as ROIs, making it less vulnerable to size\nchanges. (4) HODRF benefits from CL's lower annotation costs, allowing it to\nlearn from a larger number of images. We implemented HODRF using YOLOv7 for OD\nand EfficientNetV2 for CL and evaluated its performance on a large-scale\ndataset (4 crops, 20 diseased and healthy classes, 281K images). HODRF\noutperformed YOLOv7 alone by 5.8 to 21.5 points on healthy data and 0.6 to 7.5\npoints on macro F1 scores, and it improved macro F1 by 1.1 to 7.2 points over\nEfficientNetV2.","Link":"http://arxiv.org/pdf/2407.17906v1","Published":1721901074}
